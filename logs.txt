
==> Audit <==
|---------|-----------------------------|----------|------|---------|----------------------|----------------------|
| Command |            Args             | Profile  | User | Version |      Start Time      |       End Time       |
|---------|-----------------------------|----------|------|---------|----------------------|----------------------|
| start   | --driver=docker             | minikube | user | v1.36.0 | 03 Aug 25 14:32 CEST |                      |
| start   | --driver=docker             | minikube | user | v1.36.0 | 03 Aug 25 14:33 CEST |                      |
| start   | --driver=docker             | minikube | user | v1.36.0 | 03 Aug 25 14:33 CEST |                      |
| start   | --driver=docker             | minikube | user | v1.36.0 | 03 Aug 25 14:34 CEST |                      |
| start   | --driver=docker             | minikube | user | v1.36.0 | 03 Aug 25 15:01 CEST | 03 Aug 25 15:02 CEST |
| kubectl | -- get pods                 | minikube | user | v1.36.0 | 03 Aug 25 15:08 CEST | 03 Aug 25 15:08 CEST |
| kubectl | -- create namespace airflow | minikube | user | v1.36.0 | 03 Aug 25 15:08 CEST | 03 Aug 25 15:08 CEST |
| kubectl | -- create namespace spark   | minikube | user | v1.36.0 | 03 Aug 25 15:08 CEST | 03 Aug 25 15:08 CEST |
| start   |                             | minikube | user | v1.36.0 | 03 Aug 25 15:58 CEST | 03 Aug 25 15:58 CEST |
| kubectl | -- status                   | minikube | user | v1.36.0 | 03 Aug 25 16:14 CEST |                      |
| kubectl | --                          | minikube | user | v1.36.0 | 03 Aug 25 16:14 CEST | 03 Aug 25 16:14 CEST |
| service |                             | minikube | user | v1.36.0 | 03 Aug 25 16:15 CEST |                      |
| service | --all                       | minikube | user | v1.36.0 | 03 Aug 25 16:15 CEST |                      |
| start   |                             | minikube | user | v1.36.0 | 03 Aug 25 16:16 CEST |                      |
| start   | --driver=docker             | minikube | user | v1.36.0 | 03 Aug 25 16:24 CEST |                      |
| delete  |                             | minikube | user | v1.36.0 | 03 Aug 25 16:26 CEST | 03 Aug 25 16:26 CEST |
| start   | --driver=docker             | minikube | user | v1.36.0 | 03 Aug 25 16:26 CEST |                      |
|---------|-----------------------------|----------|------|---------|----------------------|----------------------|


==> Last Start <==
Log file created at: 2025/08/03 16:26:52
Running on machine: pop-os
Binary: Built with gc go1.24.0 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0803 16:26:52.482329   43956 out.go:345] Setting OutFile to fd 1 ...
I0803 16:26:52.482470   43956 out.go:397] isatty.IsTerminal(1) = true
I0803 16:26:52.482473   43956 out.go:358] Setting ErrFile to fd 2...
I0803 16:26:52.482475   43956 out.go:397] isatty.IsTerminal(2) = true
I0803 16:26:52.482589   43956 root.go:338] Updating PATH: /home/user/.minikube/bin
I0803 16:26:52.482981   43956 out.go:352] Setting JSON to false
I0803 16:26:52.484338   43956 start.go:130] hostinfo: {"hostname":"pop-os","uptime":1999,"bootTime":1754229213,"procs":687,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"bookworm/sid","kernelVersion":"6.12.10-76061203-generic","kernelArch":"x86_64","virtualizationSystem":"kvm","virtualizationRole":"host","hostId":"4da2b72c-c898-b0af-7285-4c31688f48f4"}
I0803 16:26:52.484405   43956 start.go:140] virtualization: kvm host
I0803 16:26:52.486832   43956 out.go:177] 😄  minikube v1.36.0 on Debian bookworm/sid
I0803 16:26:52.487651   43956 notify.go:220] Checking for updates...
I0803 16:26:52.487675   43956 driver.go:404] Setting default libvirt URI to qemu:///system
I0803 16:26:52.504541   43956 docker.go:123] docker version: linux-27.3.1:
I0803 16:26:52.504603   43956 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0803 16:26:52.542376   43956 info.go:266] docker info: {ID:29709b4f-8b7a-4c25-b8f7-b80294d4fc18 Containers:26 ContainersRunning:11 ContainersPaused:0 ContainersStopped:15 Images:10 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:88 OomKillDisable:false NGoroutines:95 SystemTime:2025-08-03 16:26:52.15791902 +0200 CEST LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:6.6.93-0-virt OperatingSystem:Alpine Linux v3.21 OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:2 MemTotal:6220406784 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:lima-rancher-desktop Labels:[] ExperimentalBuild:false ServerVersion:27.3.1 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:207ad711eabd375a01713109a8a197d197ff6542 Expected:207ad711eabd375a01713109a8a197d197ff6542} RuncCommit:{ID:7cb363254b69e10320360b63fb73e0ffb5da7bf2 Expected:7cb363254b69e10320360b63fb73e0ffb5da7bf2} InitCommit:{ID: Expected:} SecurityOptions:[name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:[WARNING: bridge-nf-call-iptables is disabled WARNING: bridge-nf-call-ip6tables is disabled] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/home/user/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.25.0] map[Name:compose Path:/home/user/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.37.1]] Warnings:<nil>}}
I0803 16:26:52.542454   43956 docker.go:318] overlay module found
I0803 16:26:52.542979   43956 out.go:177] ✨  Using the docker driver based on user configuration
I0803 16:26:52.543655   43956 start.go:304] selected driver: docker
I0803 16:26:52.543659   43956 start.go:908] validating driver "docker" against <nil>
I0803 16:26:52.543667   43956 start.go:919] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0803 16:26:52.543727   43956 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0803 16:26:52.575829   43956 info.go:266] docker info: {ID:29709b4f-8b7a-4c25-b8f7-b80294d4fc18 Containers:26 ContainersRunning:11 ContainersPaused:0 ContainersStopped:15 Images:10 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Using metacopy false] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:false KernelMemoryTCP:false CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:false BridgeNfIP6Tables:false Debug:false NFd:88 OomKillDisable:false NGoroutines:95 SystemTime:2025-08-03 16:26:52.191252109 +0200 CEST LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:6.6.93-0-virt OperatingSystem:Alpine Linux v3.21 OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:2 MemTotal:6220406784 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:lima-rancher-desktop Labels:[] ExperimentalBuild:false ServerVersion:27.3.1 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:207ad711eabd375a01713109a8a197d197ff6542 Expected:207ad711eabd375a01713109a8a197d197ff6542} RuncCommit:{ID:7cb363254b69e10320360b63fb73e0ffb5da7bf2 Expected:7cb363254b69e10320360b63fb73e0ffb5da7bf2} InitCommit:{ID: Expected:} SecurityOptions:[name=seccomp,profile=builtin name=cgroupns] ProductLicense: Warnings:[WARNING: bridge-nf-call-iptables is disabled WARNING: bridge-nf-call-ip6tables is disabled] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:/home/user/.docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-buildx] ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.25.0] map[Name:compose Path:/home/user/.docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShadowedPaths:[/usr/libexec/docker/cli-plugins/docker-compose] ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.37.1]] Warnings:<nil>}}
I0803 16:26:52.575965   43956 start_flags.go:311] no existing cluster config was found, will generate one from the flags 
I0803 16:26:52.576790   43956 start_flags.go:394] Using suggested 5884MB memory alloc based on sys=39787MB, container=5932MB
I0803 16:26:52.576909   43956 start_flags.go:958] Wait components to verify : map[apiserver:true system_pods:true]
I0803 16:26:52.578146   43956 out.go:177] 📌  Using Docker driver with root privileges
I0803 16:26:52.578620   43956 cni.go:84] Creating CNI manager for ""
I0803 16:26:52.578675   43956 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0803 16:26:52.578684   43956 start_flags.go:320] Found "bridge CNI" CNI - setting NetworkPlugin=cni
I0803 16:26:52.578735   43956 start.go:347] cluster config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:5884 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/user:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0803 16:26:52.579324   43956 out.go:177] 👍  Starting "minikube" primary control-plane node in "minikube" cluster
I0803 16:26:52.579753   43956 cache.go:121] Beginning downloading kic base image for docker with docker
I0803 16:26:52.580175   43956 out.go:177] 🚜  Pulling base image v0.0.47 ...
I0803 16:26:52.580835   43956 preload.go:131] Checking if preload exists for k8s version v1.33.1 and runtime docker
I0803 16:26:52.580857   43956 preload.go:146] Found local preload: /home/user/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.33.1-docker-overlay2-amd64.tar.lz4
I0803 16:26:52.580860   43956 cache.go:56] Caching tarball of preloaded images
I0803 16:26:52.580894   43956 image.go:81] Checking for gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b in local docker daemon
I0803 16:26:52.580934   43956 preload.go:172] Found /home/user/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.33.1-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0803 16:26:52.580943   43956 cache.go:59] Finished verifying existence of preloaded tar for v1.33.1 on docker
I0803 16:26:52.581253   43956 profile.go:143] Saving config to /home/user/.minikube/profiles/minikube/config.json ...
I0803 16:26:52.581279   43956 lock.go:35] WriteFile acquiring /home/user/.minikube/profiles/minikube/config.json: {Name:mk6327333169e91a1071710da22e1494715b6bb7 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:26:52.597964   43956 image.go:100] Found gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b in local docker daemon, skipping pull
I0803 16:26:52.597984   43956 cache.go:145] gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b exists in daemon, skipping load
I0803 16:26:52.597996   43956 cache.go:230] Successfully downloaded all kic artifacts
I0803 16:26:52.598021   43956 start.go:360] acquireMachinesLock for minikube: {Name:mkbd622808407e995359d10389220c8264ecc388 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0803 16:26:52.598102   43956 start.go:364] duration metric: took 44.055µs to acquireMachinesLock for "minikube"
I0803 16:26:52.598114   43956 start.go:93] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:5884 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/user:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} &{Name: IP: Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}
I0803 16:26:52.598164   43956 start.go:125] createHost starting for "" (driver="docker")
I0803 16:26:52.599220   43956 out.go:235] 🔥  Creating docker container (CPUs=2, Memory=5884MB) ...
I0803 16:26:52.599424   43956 start.go:159] libmachine.API.Create for "minikube" (driver="docker")
I0803 16:26:52.599455   43956 client.go:168] LocalClient.Create starting
I0803 16:26:52.599513   43956 main.go:141] libmachine: Reading certificate data from /home/user/.minikube/certs/ca.pem
I0803 16:26:52.599544   43956 main.go:141] libmachine: Decoding PEM data...
I0803 16:26:52.599558   43956 main.go:141] libmachine: Parsing certificate...
I0803 16:26:52.599612   43956 main.go:141] libmachine: Reading certificate data from /home/user/.minikube/certs/cert.pem
I0803 16:26:52.599630   43956 main.go:141] libmachine: Decoding PEM data...
I0803 16:26:52.599637   43956 main.go:141] libmachine: Parsing certificate...
I0803 16:26:52.599978   43956 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W0803 16:26:52.611904   43956 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I0803 16:26:52.611974   43956 network_create.go:284] running [docker network inspect minikube] to gather additional debugging logs...
I0803 16:26:52.611988   43956 cli_runner.go:164] Run: docker network inspect minikube
W0803 16:26:52.626091   43956 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I0803 16:26:52.626108   43956 network_create.go:287] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error response from daemon: network minikube not found
I0803 16:26:52.626117   43956 network_create.go:289] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error response from daemon: network minikube not found

** /stderr **
I0803 16:26:52.626183   43956 cli_runner.go:164] Run: docker network inspect bridge --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0803 16:26:52.640178   43956 network.go:211] skipping subnet 192.168.49.0/24 that is taken: &{IP:192.168.49.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.49.0/24 Gateway:192.168.49.1 ClientMin:192.168.49.2 ClientMax:192.168.49.254 Broadcast:192.168.49.255 IsPrivate:true Interface:{IfaceName:br-2aa945e4c93d IfaceIPv4:192.168.49.1 IfaceMTU:1500 IfaceMAC:42:58:0d:77:e9:28} reservation:<nil>}
I0803 16:26:52.640517   43956 network.go:206] using free private subnet 192.168.58.0/24: &{IP:192.168.58.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.58.0/24 Gateway:192.168.58.1 ClientMin:192.168.58.2 ClientMax:192.168.58.254 Broadcast:192.168.58.255 IsPrivate:true Interface:{IfaceName: IfaceIPv4: IfaceMTU:0 IfaceMAC:} reservation:0xc001633be0}
I0803 16:26:52.640531   43956 network_create.go:124] attempt to create docker network minikube 192.168.58.0/24 with gateway 192.168.58.1 and MTU of 1500 ...
I0803 16:26:52.640581   43956 cli_runner.go:164] Run: docker network create --driver=bridge --subnet=192.168.58.0/24 --gateway=192.168.58.1 -o --ip-masq -o --icc -o com.docker.network.driver.mtu=1500 --label=created_by.minikube.sigs.k8s.io=true --label=name.minikube.sigs.k8s.io=minikube minikube
I0803 16:26:52.818859   43956 network_create.go:108] docker network minikube 192.168.58.0/24 created
I0803 16:26:52.818887   43956 kic.go:121] calculated static IP "192.168.58.2" for the "minikube" container
I0803 16:26:52.818971   43956 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0803 16:26:52.837980   43956 cli_runner.go:164] Run: docker volume create minikube --label name.minikube.sigs.k8s.io=minikube --label created_by.minikube.sigs.k8s.io=true
I0803 16:26:52.855704   43956 oci.go:103] Successfully created a docker volume minikube
I0803 16:26:52.855762   43956 cli_runner.go:164] Run: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b -d /var/lib
I0803 16:26:53.432477   43956 oci.go:107] Successfully prepared a docker volume minikube
I0803 16:26:53.432524   43956 preload.go:131] Checking if preload exists for k8s version v1.33.1 and runtime docker
I0803 16:26:53.432554   43956 kic.go:194] Starting extracting preloaded images to volume ...
I0803 16:26:53.432648   43956 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v /home/user/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.33.1-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b -I lz4 -xf /preloaded.tar -C /extractDir
I0803 16:26:57.023219   43956 cli_runner.go:217] Completed: docker run --rm --entrypoint /usr/bin/tar -v /home/user/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.33.1-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b -I lz4 -xf /preloaded.tar -C /extractDir: (3.590522029s)
I0803 16:26:57.023249   43956 kic.go:203] duration metric: took 3.590693653s to extract preloaded images to volume ...
W0803 16:26:57.023358   43956 cgroups_linux.go:77] Your kernel does not support swap limit capabilities or the cgroup is not mounted.
W0803 16:26:57.023375   43956 oci.go:249] Your kernel does not support CPU cfs period/quota or the cgroup is not mounted.
I0803 16:26:57.023414   43956 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0803 16:26:57.055655   43956 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.58.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=5884mb -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b
I0803 16:26:57.371834   43956 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Running}}
I0803 16:26:57.385126   43956 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0803 16:26:57.400401   43956 cli_runner.go:164] Run: docker exec minikube stat /var/lib/dpkg/alternatives/iptables
I0803 16:26:57.453151   43956 oci.go:144] the created container "minikube" has a running status.
I0803 16:26:57.453179   43956 kic.go:225] Creating ssh key for kic: /home/user/.minikube/machines/minikube/id_rsa...
I0803 16:26:57.527788   43956 kic_runner.go:191] docker (temp): /home/user/.minikube/machines/minikube/id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0803 16:26:57.544955   43956 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0803 16:26:57.557789   43956 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0803 16:26:57.557799   43956 kic_runner.go:114] Args: [docker exec --privileged minikube chown docker:docker /home/docker/.ssh/authorized_keys]
I0803 16:26:57.631882   43956 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0803 16:26:57.648426   43956 machine.go:93] provisionDockerMachine start ...
I0803 16:26:57.648551   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:26:57.662754   43956 main.go:141] libmachine: Using SSH client type: native
I0803 16:26:57.662956   43956 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bba0] 0x83e8a0 <nil>  [] 0s} 127.0.0.1 32773 <nil> <nil>}
I0803 16:26:57.662965   43956 main.go:141] libmachine: About to run SSH command:
hostname
I0803 16:26:57.663103   43956 main.go:141] libmachine: Error dialing TCP: dial tcp 127.0.0.1:32773: connect: connection refused
I0803 16:27:00.806757   43956 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0803 16:27:00.806785   43956 ubuntu.go:169] provisioning hostname "minikube"
I0803 16:27:00.806935   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:00.825932   43956 main.go:141] libmachine: Using SSH client type: native
I0803 16:27:00.826257   43956 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bba0] 0x83e8a0 <nil>  [] 0s} 127.0.0.1 32773 <nil> <nil>}
I0803 16:27:00.826269   43956 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0803 16:27:00.966372   43956 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0803 16:27:00.966425   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:00.981813   43956 main.go:141] libmachine: Using SSH client type: native
I0803 16:27:00.982080   43956 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bba0] 0x83e8a0 <nil>  [] 0s} 127.0.0.1 32773 <nil> <nil>}
I0803 16:27:00.982094   43956 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0803 16:27:01.104342   43956 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0803 16:27:01.104393   43956 ubuntu.go:175] set auth options {CertDir:/home/user/.minikube CaCertPath:/home/user/.minikube/certs/ca.pem CaPrivateKeyPath:/home/user/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/user/.minikube/machines/server.pem ServerKeyPath:/home/user/.minikube/machines/server-key.pem ClientKeyPath:/home/user/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/user/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/user/.minikube}
I0803 16:27:01.104417   43956 ubuntu.go:177] setting up certificates
I0803 16:27:01.104430   43956 provision.go:84] configureAuth start
I0803 16:27:01.104513   43956 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0803 16:27:01.124077   43956 provision.go:143] copyHostCerts
I0803 16:27:01.124137   43956 exec_runner.go:144] found /home/user/.minikube/ca.pem, removing ...
I0803 16:27:01.124143   43956 exec_runner.go:203] rm: /home/user/.minikube/ca.pem
I0803 16:27:01.124224   43956 exec_runner.go:151] cp: /home/user/.minikube/certs/ca.pem --> /home/user/.minikube/ca.pem (1070 bytes)
I0803 16:27:01.124337   43956 exec_runner.go:144] found /home/user/.minikube/cert.pem, removing ...
I0803 16:27:01.124342   43956 exec_runner.go:203] rm: /home/user/.minikube/cert.pem
I0803 16:27:01.124376   43956 exec_runner.go:151] cp: /home/user/.minikube/certs/cert.pem --> /home/user/.minikube/cert.pem (1115 bytes)
I0803 16:27:01.124452   43956 exec_runner.go:144] found /home/user/.minikube/key.pem, removing ...
I0803 16:27:01.124456   43956 exec_runner.go:203] rm: /home/user/.minikube/key.pem
I0803 16:27:01.124489   43956 exec_runner.go:151] cp: /home/user/.minikube/certs/key.pem --> /home/user/.minikube/key.pem (1675 bytes)
I0803 16:27:01.124551   43956 provision.go:117] generating server cert: /home/user/.minikube/machines/server.pem ca-key=/home/user/.minikube/certs/ca.pem private-key=/home/user/.minikube/certs/ca-key.pem org=user.minikube san=[127.0.0.1 192.168.58.2 localhost minikube]
I0803 16:27:01.181418   43956 provision.go:177] copyRemoteCerts
I0803 16:27:01.181448   43956 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0803 16:27:01.181468   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:01.194526   43956 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32773 SSHKeyPath:/home/user/.minikube/machines/minikube/id_rsa Username:docker}
I0803 16:27:01.297104   43956 ssh_runner.go:362] scp /home/user/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1070 bytes)
I0803 16:27:01.313373   43956 ssh_runner.go:362] scp /home/user/.minikube/machines/server.pem --> /etc/docker/server.pem (1176 bytes)
I0803 16:27:01.331789   43956 ssh_runner.go:362] scp /home/user/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0803 16:27:01.352884   43956 provision.go:87] duration metric: took 248.444084ms to configureAuth
I0803 16:27:01.352896   43956 ubuntu.go:193] setting minikube options for container-runtime
I0803 16:27:01.353059   43956 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.33.1
I0803 16:27:01.353095   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:01.367888   43956 main.go:141] libmachine: Using SSH client type: native
I0803 16:27:01.368106   43956 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bba0] 0x83e8a0 <nil>  [] 0s} 127.0.0.1 32773 <nil> <nil>}
I0803 16:27:01.368112   43956 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0803 16:27:01.500183   43956 main.go:141] libmachine: SSH cmd err, output: <nil>: overlay

I0803 16:27:01.500194   43956 ubuntu.go:71] root file system type: overlay
I0803 16:27:01.500292   43956 provision.go:314] Updating docker unit: /lib/systemd/system/docker.service ...
I0803 16:27:01.500357   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:01.516267   43956 main.go:141] libmachine: Using SSH client type: native
I0803 16:27:01.516500   43956 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bba0] 0x83e8a0 <nil>  [] 0s} 127.0.0.1 32773 <nil> <nil>}
I0803 16:27:01.516564   43956 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0803 16:27:01.661671   43956 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0803 16:27:01.661725   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:01.678191   43956 main.go:141] libmachine: Using SSH client type: native
I0803 16:27:01.678413   43956 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x83bba0] 0x83e8a0 <nil>  [] 0s} 127.0.0.1 32773 <nil> <nil>}
I0803 16:27:01.678423   43956 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0803 16:27:04.056772   43956 main.go:141] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2025-04-18 09:50:48.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2025-08-03 14:27:01.270000000 +0000
@@ -1,46 +1,49 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target nss-lookup.target docker.socket firewalld.service containerd.service time-set.target
-Wants=network-online.target containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
+Wants=network-online.target
 Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutStartSec=0
-RestartSec=2
-Restart=always
+Restart=on-failure
 
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
+LimitNOFILE=infinity
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0803 16:27:04.056801   43956 machine.go:96] duration metric: took 6.408360242s to provisionDockerMachine
I0803 16:27:04.056809   43956 client.go:171] duration metric: took 11.457349614s to LocalClient.Create
I0803 16:27:04.056821   43956 start.go:167] duration metric: took 11.457397769s to libmachine.API.Create "minikube"
I0803 16:27:04.056826   43956 start.go:293] postStartSetup for "minikube" (driver="docker")
I0803 16:27:04.056834   43956 start.go:322] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0803 16:27:04.056886   43956 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0803 16:27:04.056924   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:04.072081   43956 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32773 SSHKeyPath:/home/user/.minikube/machines/minikube/id_rsa Username:docker}
I0803 16:27:04.162960   43956 ssh_runner.go:195] Run: cat /etc/os-release
I0803 16:27:04.165954   43956 main.go:141] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0803 16:27:04.165973   43956 main.go:141] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0803 16:27:04.165980   43956 main.go:141] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0803 16:27:04.165984   43956 info.go:137] Remote host: Ubuntu 22.04.5 LTS
I0803 16:27:04.165993   43956 filesync.go:126] Scanning /home/user/.minikube/addons for local assets ...
I0803 16:27:04.166050   43956 filesync.go:126] Scanning /home/user/.minikube/files for local assets ...
I0803 16:27:04.166065   43956 start.go:296] duration metric: took 109.235533ms for postStartSetup
I0803 16:27:04.166332   43956 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0803 16:27:04.180108   43956 profile.go:143] Saving config to /home/user/.minikube/profiles/minikube/config.json ...
I0803 16:27:04.180391   43956 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0803 16:27:04.180422   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:04.193260   43956 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32773 SSHKeyPath:/home/user/.minikube/machines/minikube/id_rsa Username:docker}
I0803 16:27:04.284948   43956 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0803 16:27:04.289662   43956 start.go:128] duration metric: took 11.691488207s to createHost
I0803 16:27:04.289674   43956 start.go:83] releasing machines lock for "minikube", held for 11.691566252s
I0803 16:27:04.289732   43956 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0803 16:27:04.305293   43956 ssh_runner.go:195] Run: cat /version.json
I0803 16:27:04.305329   43956 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0803 16:27:04.305351   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:04.305405   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:04.320118   43956 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32773 SSHKeyPath:/home/user/.minikube/machines/minikube/id_rsa Username:docker}
I0803 16:27:04.320278   43956 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32773 SSHKeyPath:/home/user/.minikube/machines/minikube/id_rsa Username:docker}
I0803 16:27:04.416319   43956 ssh_runner.go:195] Run: systemctl --version
I0803 16:27:04.576444   43956 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
I0803 16:27:04.583164   43956 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f -name *loopback.conf* -not -name *.mk_disabled -exec sh -c "grep -q loopback {} && ( grep -q name {} || sudo sed -i '/"type": "loopback"/i \ \ \ \ "name": "loopback",' {} ) && sudo sed -i 's|"cniVersion": ".*"|"cniVersion": "1.0.0"|g' {}" ;
I0803 16:27:04.605437   43956 cni.go:230] loopback cni configuration patched: "/etc/cni/net.d/*loopback.conf*" found
I0803 16:27:04.605489   43956 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%p, " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0803 16:27:04.630637   43956 cni.go:262] disabled [/etc/cni/net.d/87-podman-bridge.conflist, /etc/cni/net.d/100-crio-bridge.conf] bridge cni config(s)
I0803 16:27:04.630660   43956 start.go:495] detecting cgroup driver to use...
I0803 16:27:04.630688   43956 detect.go:190] detected "systemd" cgroup driver on host os
I0803 16:27:04.630760   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0803 16:27:04.641875   43956 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.10"|' /etc/containerd/config.toml"
I0803 16:27:04.650178   43956 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0803 16:27:04.660370   43956 containerd.go:146] configuring containerd to use "systemd" as cgroup driver...
I0803 16:27:04.660425   43956 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = true|g' /etc/containerd/config.toml"
I0803 16:27:04.668296   43956 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0803 16:27:04.675515   43956 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0803 16:27:04.683160   43956 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0803 16:27:04.691845   43956 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0803 16:27:04.699317   43956 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0803 16:27:04.707060   43956 ssh_runner.go:195] Run: sh -c "sudo sed -i '/^ *enable_unprivileged_ports = .*/d' /etc/containerd/config.toml"
I0803 16:27:04.717623   43956 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)\[plugins."io.containerd.grpc.v1.cri"\]|&\n\1  enable_unprivileged_ports = true|' /etc/containerd/config.toml"
I0803 16:27:04.725667   43956 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0803 16:27:04.733121   43956 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0803 16:27:04.739592   43956 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0803 16:27:04.823128   43956 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0803 16:27:04.921726   43956 start.go:495] detecting cgroup driver to use...
I0803 16:27:04.921791   43956 detect.go:190] detected "systemd" cgroup driver on host os
I0803 16:27:04.921862   43956 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0803 16:27:04.933296   43956 cruntime.go:279] skipping containerd shutdown because we are bound to it
I0803 16:27:04.933366   43956 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0803 16:27:04.944218   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0803 16:27:04.957157   43956 ssh_runner.go:195] Run: which cri-dockerd
I0803 16:27:04.961013   43956 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0803 16:27:04.971053   43956 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (190 bytes)
I0803 16:27:04.984054   43956 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0803 16:27:05.036197   43956 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0803 16:27:05.120988   43956 docker.go:587] configuring docker to use "systemd" as cgroup driver...
I0803 16:27:05.121061   43956 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (129 bytes)
I0803 16:27:05.133484   43956 ssh_runner.go:195] Run: sudo systemctl reset-failed docker
I0803 16:27:05.141389   43956 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0803 16:27:05.219752   43956 ssh_runner.go:195] Run: sudo systemctl restart docker
I0803 16:27:08.633008   43956 ssh_runner.go:235] Completed: sudo systemctl restart docker: (3.413235245s)
I0803 16:27:08.633059   43956 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.socket
I0803 16:27:08.642270   43956 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0803 16:27:08.650558   43956 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0803 16:27:08.696300   43956 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0803 16:27:08.785683   43956 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0803 16:27:08.871256   43956 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0803 16:27:08.898181   43956 ssh_runner.go:195] Run: sudo systemctl reset-failed cri-docker.service
I0803 16:27:08.906298   43956 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0803 16:27:08.980305   43956 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.service
I0803 16:27:09.076285   43956 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service cri-docker.service
I0803 16:27:09.084325   43956 start.go:542] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0803 16:27:09.084373   43956 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0803 16:27:09.087387   43956 start.go:563] Will wait 60s for crictl version
I0803 16:27:09.087446   43956 ssh_runner.go:195] Run: which crictl
I0803 16:27:09.090460   43956 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0803 16:27:09.133763   43956 start.go:579] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  28.1.1
RuntimeApiVersion:  v1
I0803 16:27:09.133810   43956 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0803 16:27:09.166237   43956 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0803 16:27:09.187559   43956 out.go:235] 🐳  Preparing Kubernetes v1.33.1 on Docker 28.1.1 ...
I0803 16:27:09.187642   43956 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0803 16:27:09.200781   43956 ssh_runner.go:195] Run: grep 192.168.58.1	host.minikube.internal$ /etc/hosts
I0803 16:27:09.203954   43956 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.58.1	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0803 16:27:09.212960   43956 kubeadm.go:875] updating cluster {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:5884 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.58.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/user:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s} ...
I0803 16:27:09.213062   43956 preload.go:131] Checking if preload exists for k8s version v1.33.1 and runtime docker
I0803 16:27:09.213113   43956 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0803 16:27:09.227665   43956 docker.go:702] Got preloaded images: -- stdout --
registry.k8s.io/kube-scheduler:v1.33.1
registry.k8s.io/kube-apiserver:v1.33.1
registry.k8s.io/kube-controller-manager:v1.33.1
registry.k8s.io/kube-proxy:v1.33.1
registry.k8s.io/etcd:3.5.21-0
registry.k8s.io/coredns/coredns:v1.12.0
registry.k8s.io/pause:3.10
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0803 16:27:09.227674   43956 docker.go:632] Images already preloaded, skipping extraction
I0803 16:27:09.227724   43956 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0803 16:27:09.240773   43956 docker.go:702] Got preloaded images: -- stdout --
registry.k8s.io/kube-scheduler:v1.33.1
registry.k8s.io/kube-apiserver:v1.33.1
registry.k8s.io/kube-controller-manager:v1.33.1
registry.k8s.io/kube-proxy:v1.33.1
registry.k8s.io/etcd:3.5.21-0
registry.k8s.io/coredns/coredns:v1.12.0
registry.k8s.io/pause:3.10
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0803 16:27:09.240784   43956 cache_images.go:84] Images are preloaded, skipping loading
I0803 16:27:09.240791   43956 kubeadm.go:926] updating node { 192.168.58.2 8443 v1.33.1 docker true true} ...
I0803 16:27:09.240860   43956 kubeadm.go:938] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.33.1/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.58.2

[Install]
 config:
{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:}
I0803 16:27:09.240905   43956 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0803 16:27:09.303290   43956 cni.go:84] Creating CNI manager for ""
I0803 16:27:09.303313   43956 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0803 16:27:09.303323   43956 kubeadm.go:84] Using pod CIDR: 10.244.0.0/16
I0803 16:27:09.303343   43956 kubeadm.go:189] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.58.2 APIServerPort:8443 KubernetesVersion:v1.33.1 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.58.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.58.2 CgroupDriver:systemd ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[containerRuntimeEndpoint:unix:///var/run/cri-dockerd.sock hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0803 16:27:09.303467   43956 kubeadm.go:195] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta4
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.58.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    - name: "node-ip"
      value: "192.168.58.2"
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta4
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.58.2"]
  extraArgs:
    - name: "enable-admission-plugins"
      value: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    - name: "allocate-node-cidrs"
      value: "true"
    - name: "leader-elect"
      value: "false"
scheduler:
  extraArgs:
    - name: "leader-elect"
      value: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      - name: "proxy-refresh-interval"
        value: "70000"
kubernetesVersion: v1.33.1
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: systemd
containerRuntimeEndpoint: unix:///var/run/cri-dockerd.sock
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0803 16:27:09.303550   43956 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.33.1
I0803 16:27:09.310828   43956 binaries.go:44] Found k8s binaries, skipping transfer
I0803 16:27:09.310877   43956 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0803 16:27:09.316358   43956 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (307 bytes)
I0803 16:27:09.327986   43956 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0803 16:27:09.340607   43956 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2285 bytes)
I0803 16:27:09.351624   43956 ssh_runner.go:195] Run: grep 192.168.58.2	control-plane.minikube.internal$ /etc/hosts
I0803 16:27:09.354300   43956 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.58.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0803 16:27:09.361688   43956 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0803 16:27:09.438997   43956 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0803 16:27:09.468655   43956 certs.go:68] Setting up /home/user/.minikube/profiles/minikube for IP: 192.168.58.2
I0803 16:27:09.468663   43956 certs.go:194] generating shared ca certs ...
I0803 16:27:09.468675   43956 certs.go:226] acquiring lock for ca certs: {Name:mke32e43b48026f434383aa025803b9c56ebd98b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:27:09.468807   43956 certs.go:235] skipping valid "minikubeCA" ca cert: /home/user/.minikube/ca.key
I0803 16:27:09.468855   43956 certs.go:235] skipping valid "proxyClientCA" ca cert: /home/user/.minikube/proxy-client-ca.key
I0803 16:27:09.468861   43956 certs.go:256] generating profile certs ...
I0803 16:27:09.468908   43956 certs.go:363] generating signed profile cert for "minikube-user": /home/user/.minikube/profiles/minikube/client.key
I0803 16:27:09.468921   43956 crypto.go:68] Generating cert /home/user/.minikube/profiles/minikube/client.crt with IP's: []
I0803 16:27:09.538667   43956 crypto.go:156] Writing cert to /home/user/.minikube/profiles/minikube/client.crt ...
I0803 16:27:09.538677   43956 lock.go:35] WriteFile acquiring /home/user/.minikube/profiles/minikube/client.crt: {Name:mka9c1a5e835a20e74006b58a7759660b6a78a2f Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:27:09.538826   43956 crypto.go:164] Writing key to /home/user/.minikube/profiles/minikube/client.key ...
I0803 16:27:09.538830   43956 lock.go:35] WriteFile acquiring /home/user/.minikube/profiles/minikube/client.key: {Name:mke5de9237360705a6b08eefae35bd1f5421d2e1 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:27:09.538871   43956 certs.go:363] generating signed profile cert for "minikube": /home/user/.minikube/profiles/minikube/apiserver.key.502bbb95
I0803 16:27:09.538876   43956 crypto.go:68] Generating cert /home/user/.minikube/profiles/minikube/apiserver.crt.502bbb95 with IP's: [10.96.0.1 127.0.0.1 10.0.0.1 192.168.58.2]
I0803 16:27:09.587968   43956 crypto.go:156] Writing cert to /home/user/.minikube/profiles/minikube/apiserver.crt.502bbb95 ...
I0803 16:27:09.587978   43956 lock.go:35] WriteFile acquiring /home/user/.minikube/profiles/minikube/apiserver.crt.502bbb95: {Name:mka77d3c5e7bf619a4f72979974bdb9c118a7a68 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:27:09.588107   43956 crypto.go:164] Writing key to /home/user/.minikube/profiles/minikube/apiserver.key.502bbb95 ...
I0803 16:27:09.588109   43956 lock.go:35] WriteFile acquiring /home/user/.minikube/profiles/minikube/apiserver.key.502bbb95: {Name:mkdf4a942b2d4d8aa5d69168f44f3634cfed93ba Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:27:09.588139   43956 certs.go:381] copying /home/user/.minikube/profiles/minikube/apiserver.crt.502bbb95 -> /home/user/.minikube/profiles/minikube/apiserver.crt
I0803 16:27:09.588205   43956 certs.go:385] copying /home/user/.minikube/profiles/minikube/apiserver.key.502bbb95 -> /home/user/.minikube/profiles/minikube/apiserver.key
I0803 16:27:09.588228   43956 certs.go:363] generating signed profile cert for "aggregator": /home/user/.minikube/profiles/minikube/proxy-client.key
I0803 16:27:09.588233   43956 crypto.go:68] Generating cert /home/user/.minikube/profiles/minikube/proxy-client.crt with IP's: []
I0803 16:27:09.622283   43956 crypto.go:156] Writing cert to /home/user/.minikube/profiles/minikube/proxy-client.crt ...
I0803 16:27:09.622291   43956 lock.go:35] WriteFile acquiring /home/user/.minikube/profiles/minikube/proxy-client.crt: {Name:mke1f0483b419ee897a73431cf7d3912dc6b1e41 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:27:09.622377   43956 crypto.go:164] Writing key to /home/user/.minikube/profiles/minikube/proxy-client.key ...
I0803 16:27:09.622379   43956 lock.go:35] WriteFile acquiring /home/user/.minikube/profiles/minikube/proxy-client.key: {Name:mkb31655180fc53f8c7371a942a88835985e38f4 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:27:09.622458   43956 certs.go:484] found cert: /home/user/.minikube/certs/ca-key.pem (1675 bytes)
I0803 16:27:09.622473   43956 certs.go:484] found cert: /home/user/.minikube/certs/ca.pem (1070 bytes)
I0803 16:27:09.622482   43956 certs.go:484] found cert: /home/user/.minikube/certs/cert.pem (1115 bytes)
I0803 16:27:09.622490   43956 certs.go:484] found cert: /home/user/.minikube/certs/key.pem (1675 bytes)
I0803 16:27:09.622871   43956 ssh_runner.go:362] scp /home/user/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0803 16:27:09.645592   43956 ssh_runner.go:362] scp /home/user/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I0803 16:27:09.663060   43956 ssh_runner.go:362] scp /home/user/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0803 16:27:09.681932   43956 ssh_runner.go:362] scp /home/user/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0803 16:27:09.701211   43956 ssh_runner.go:362] scp /home/user/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1411 bytes)
I0803 16:27:09.717280   43956 ssh_runner.go:362] scp /home/user/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0803 16:27:09.733272   43956 ssh_runner.go:362] scp /home/user/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0803 16:27:09.750090   43956 ssh_runner.go:362] scp /home/user/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0803 16:27:09.765003   43956 ssh_runner.go:362] scp /home/user/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0803 16:27:09.784245   43956 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (740 bytes)
I0803 16:27:09.795775   43956 ssh_runner.go:195] Run: openssl version
I0803 16:27:09.801132   43956 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0803 16:27:09.809160   43956 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0803 16:27:09.812682   43956 certs.go:528] hashing: -rw-r--r-- 1 root root 1111 Aug  3 13:02 /usr/share/ca-certificates/minikubeCA.pem
I0803 16:27:09.812738   43956 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0803 16:27:09.817669   43956 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0803 16:27:09.824094   43956 ssh_runner.go:195] Run: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt
I0803 16:27:09.826719   43956 certs.go:399] 'apiserver-kubelet-client' cert doesn't exist, likely first start: stat /var/lib/minikube/certs/apiserver-kubelet-client.crt: Process exited with status 1
stdout:

stderr:
stat: cannot statx '/var/lib/minikube/certs/apiserver-kubelet-client.crt': No such file or directory
I0803 16:27:09.826751   43956 kubeadm.go:392] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.47@sha256:6ed579c9292b4370177b7ef3c42cc4b4a6dcd0735a1814916cbc22c8bf38412b Memory:5884 CPUs:2 DiskSize:20000 Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:8443 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.33.1 ClusterName:minikube Namespace:default APIServerHAVIP: APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI:} Nodes:[{Name: IP:192.168.58.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/user:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 GPUs: AutoPauseInterval:1m0s}
I0803 16:27:09.826837   43956 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0803 16:27:09.839708   43956 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0803 16:27:09.847877   43956 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0803 16:27:09.855379   43956 kubeadm.go:214] ignoring SystemVerification for kubeadm because of docker driver
I0803 16:27:09.855427   43956 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0803 16:27:09.862295   43956 kubeadm.go:155] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0803 16:27:09.862301   43956 kubeadm.go:157] found existing configuration files:

I0803 16:27:09.862346   43956 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0803 16:27:09.869894   43956 kubeadm.go:163] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/admin.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/admin.conf: No such file or directory
I0803 16:27:09.869958   43956 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/admin.conf
I0803 16:27:09.878231   43956 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0803 16:27:09.884483   43956 kubeadm.go:163] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/kubelet.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/kubelet.conf: No such file or directory
I0803 16:27:09.884531   43956 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/kubelet.conf
I0803 16:27:09.890568   43956 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0803 16:27:09.896857   43956 kubeadm.go:163] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/controller-manager.conf: No such file or directory
I0803 16:27:09.896899   43956 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0803 16:27:09.902737   43956 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0803 16:27:09.909782   43956 kubeadm.go:163] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
grep: /etc/kubernetes/scheduler.conf: No such file or directory
I0803 16:27:09.909829   43956 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0803 16:27:09.916271   43956 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.33.1:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0803 16:27:09.944093   43956 kubeadm.go:310] [init] Using Kubernetes version: v1.33.1
I0803 16:27:09.944131   43956 kubeadm.go:310] [preflight] Running pre-flight checks
I0803 16:27:10.027055   43956 kubeadm.go:310] [preflight] Pulling images required for setting up a Kubernetes cluster
I0803 16:27:10.027141   43956 kubeadm.go:310] [preflight] This might take a minute or two, depending on the speed of your internet connection
I0803 16:27:10.027214   43956 kubeadm.go:310] [preflight] You can also perform this action beforehand using 'kubeadm config images pull'
I0803 16:27:10.039640   43956 kubeadm.go:310] [certs] Using certificateDir folder "/var/lib/minikube/certs"
I0803 16:27:10.042390   43956 out.go:235]     ▪ Generating certificates and keys ...
I0803 16:27:10.042460   43956 kubeadm.go:310] [certs] Using existing ca certificate authority
I0803 16:27:10.042513   43956 kubeadm.go:310] [certs] Using existing apiserver certificate and key on disk
I0803 16:27:10.181234   43956 kubeadm.go:310] [certs] Generating "apiserver-kubelet-client" certificate and key
I0803 16:27:10.226033   43956 kubeadm.go:310] [certs] Generating "front-proxy-ca" certificate and key
I0803 16:27:10.330159   43956 kubeadm.go:310] [certs] Generating "front-proxy-client" certificate and key
I0803 16:27:10.551229   43956 kubeadm.go:310] [certs] Generating "etcd/ca" certificate and key
I0803 16:27:10.648979   43956 kubeadm.go:310] [certs] Generating "etcd/server" certificate and key
I0803 16:27:10.649068   43956 kubeadm.go:310] [certs] etcd/server serving cert is signed for DNS names [localhost minikube] and IPs [192.168.58.2 127.0.0.1 ::1]
I0803 16:27:10.878765   43956 kubeadm.go:310] [certs] Generating "etcd/peer" certificate and key
I0803 16:27:10.878882   43956 kubeadm.go:310] [certs] etcd/peer serving cert is signed for DNS names [localhost minikube] and IPs [192.168.58.2 127.0.0.1 ::1]
I0803 16:27:10.956394   43956 kubeadm.go:310] [certs] Generating "etcd/healthcheck-client" certificate and key
I0803 16:27:11.115202   43956 kubeadm.go:310] [certs] Generating "apiserver-etcd-client" certificate and key
I0803 16:27:11.197858   43956 kubeadm.go:310] [certs] Generating "sa" key and public key
I0803 16:27:11.197905   43956 kubeadm.go:310] [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
I0803 16:27:11.348496   43956 kubeadm.go:310] [kubeconfig] Writing "admin.conf" kubeconfig file
I0803 16:27:11.419272   43956 kubeadm.go:310] [kubeconfig] Writing "super-admin.conf" kubeconfig file
I0803 16:27:11.515666   43956 kubeadm.go:310] [kubeconfig] Writing "kubelet.conf" kubeconfig file
I0803 16:27:11.627859   43956 kubeadm.go:310] [kubeconfig] Writing "controller-manager.conf" kubeconfig file
I0803 16:27:11.680331   43956 kubeadm.go:310] [kubeconfig] Writing "scheduler.conf" kubeconfig file
I0803 16:27:11.680404   43956 kubeadm.go:310] [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
I0803 16:27:11.681695   43956 kubeadm.go:310] [control-plane] Using manifest folder "/etc/kubernetes/manifests"
I0803 16:27:11.682937   43956 out.go:235]     ▪ Booting up control plane ...
I0803 16:27:11.683026   43956 kubeadm.go:310] [control-plane] Creating static Pod manifest for "kube-apiserver"
I0803 16:27:11.683088   43956 kubeadm.go:310] [control-plane] Creating static Pod manifest for "kube-controller-manager"
I0803 16:27:11.683139   43956 kubeadm.go:310] [control-plane] Creating static Pod manifest for "kube-scheduler"
I0803 16:27:11.698139   43956 kubeadm.go:310] [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I0803 16:27:11.703001   43956 kubeadm.go:310] [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0803 16:27:11.703032   43956 kubeadm.go:310] [kubelet-start] Starting the kubelet
I0803 16:27:11.819287   43956 kubeadm.go:310] [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests"
I0803 16:27:11.819375   43956 kubeadm.go:310] [kubelet-check] Waiting for a healthy kubelet at http://127.0.0.1:10248/healthz. This can take up to 4m0s
I0803 16:27:12.319910   43956 kubeadm.go:310] [kubelet-check] The kubelet is healthy after 500.81352ms
I0803 16:27:12.323066   43956 kubeadm.go:310] [control-plane-check] Waiting for healthy control plane components. This can take up to 4m0s
I0803 16:27:12.323140   43956 kubeadm.go:310] [control-plane-check] Checking kube-apiserver at https://192.168.58.2:8443/livez
I0803 16:27:12.323228   43956 kubeadm.go:310] [control-plane-check] Checking kube-controller-manager at https://127.0.0.1:10257/healthz
I0803 16:27:12.323303   43956 kubeadm.go:310] [control-plane-check] Checking kube-scheduler at https://127.0.0.1:10259/livez
I0803 16:27:14.129162   43956 kubeadm.go:310] [control-plane-check] kube-controller-manager is healthy after 1.805732595s
I0803 16:27:14.799609   43956 kubeadm.go:310] [control-plane-check] kube-scheduler is healthy after 2.476266936s
I0803 16:27:16.326455   43956 kubeadm.go:310] [control-plane-check] kube-apiserver is healthy after 4.001444608s
I0803 16:27:16.336578   43956 kubeadm.go:310] [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
I0803 16:27:16.347524   43956 kubeadm.go:310] [kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the configuration for the kubelets in the cluster
I0803 16:27:16.361187   43956 kubeadm.go:310] [upload-certs] Skipping phase. Please see --upload-certs
I0803 16:27:16.361363   43956 kubeadm.go:310] [mark-control-plane] Marking the node minikube as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
I0803 16:27:16.370243   43956 kubeadm.go:310] [bootstrap-token] Using token: e6e1dv.44w1dbsr9w0belhz
I0803 16:27:16.370740   43956 out.go:235]     ▪ Configuring RBAC rules ...
I0803 16:27:16.370837   43956 kubeadm.go:310] [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
I0803 16:27:16.375530   43956 kubeadm.go:310] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
I0803 16:27:16.379744   43956 kubeadm.go:310] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
I0803 16:27:16.382905   43956 kubeadm.go:310] [bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
I0803 16:27:16.385237   43956 kubeadm.go:310] [bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
I0803 16:27:16.389128   43956 kubeadm.go:310] [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
I0803 16:27:16.736649   43956 kubeadm.go:310] [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
I0803 16:27:17.148866   43956 kubeadm.go:310] [addons] Applied essential addon: CoreDNS
I0803 16:27:17.735842   43956 kubeadm.go:310] [addons] Applied essential addon: kube-proxy
I0803 16:27:17.740413   43956 kubeadm.go:310] 
I0803 16:27:17.740521   43956 kubeadm.go:310] Your Kubernetes control-plane has initialized successfully!
I0803 16:27:17.740529   43956 kubeadm.go:310] 
I0803 16:27:17.740643   43956 kubeadm.go:310] To start using your cluster, you need to run the following as a regular user:
I0803 16:27:17.740654   43956 kubeadm.go:310] 
I0803 16:27:17.740692   43956 kubeadm.go:310]   mkdir -p $HOME/.kube
I0803 16:27:17.740783   43956 kubeadm.go:310]   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
I0803 16:27:17.740884   43956 kubeadm.go:310]   sudo chown $(id -u):$(id -g) $HOME/.kube/config
I0803 16:27:17.740896   43956 kubeadm.go:310] 
I0803 16:27:17.741023   43956 kubeadm.go:310] Alternatively, if you are the root user, you can run:
I0803 16:27:17.741030   43956 kubeadm.go:310] 
I0803 16:27:17.741118   43956 kubeadm.go:310]   export KUBECONFIG=/etc/kubernetes/admin.conf
I0803 16:27:17.741130   43956 kubeadm.go:310] 
I0803 16:27:17.741215   43956 kubeadm.go:310] You should now deploy a pod network to the cluster.
I0803 16:27:17.741338   43956 kubeadm.go:310] Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
I0803 16:27:17.741460   43956 kubeadm.go:310]   https://kubernetes.io/docs/concepts/cluster-administration/addons/
I0803 16:27:17.741467   43956 kubeadm.go:310] 
I0803 16:27:17.741645   43956 kubeadm.go:310] You can now join any number of control-plane nodes by copying certificate authorities
I0803 16:27:17.741784   43956 kubeadm.go:310] and service account keys on each node and then running the following as root:
I0803 16:27:17.741791   43956 kubeadm.go:310] 
I0803 16:27:17.741974   43956 kubeadm.go:310]   kubeadm join control-plane.minikube.internal:8443 --token e6e1dv.44w1dbsr9w0belhz \
I0803 16:27:17.742170   43956 kubeadm.go:310] 	--discovery-token-ca-cert-hash sha256:a6c495f3083483bef999e49c9945a6f1d1408ad989238b49a0c57abc6be06ecf \
I0803 16:27:17.742206   43956 kubeadm.go:310] 	--control-plane 
I0803 16:27:17.742221   43956 kubeadm.go:310] 
I0803 16:27:17.742387   43956 kubeadm.go:310] Then you can join any number of worker nodes by running the following on each as root:
I0803 16:27:17.742393   43956 kubeadm.go:310] 
I0803 16:27:17.742564   43956 kubeadm.go:310] kubeadm join control-plane.minikube.internal:8443 --token e6e1dv.44w1dbsr9w0belhz \
I0803 16:27:17.742802   43956 kubeadm.go:310] 	--discovery-token-ca-cert-hash sha256:a6c495f3083483bef999e49c9945a6f1d1408ad989238b49a0c57abc6be06ecf 
I0803 16:27:17.743095   43956 kubeadm.go:310] 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0803 16:27:17.743122   43956 cni.go:84] Creating CNI manager for ""
I0803 16:27:17.743137   43956 cni.go:158] "docker" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0803 16:27:17.744040   43956 out.go:177] 🔗  Configuring bridge CNI (Container Networking Interface) ...
I0803 16:27:17.744548   43956 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0803 16:27:17.753495   43956 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (496 bytes)
I0803 16:27:17.765556   43956 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0803 16:27:17.765620   43956 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.33.1/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0803 16:27:17.765633   43956 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.33.1/kubectl --kubeconfig=/var/lib/minikube/kubeconfig label --overwrite nodes minikube minikube.k8s.io/updated_at=2025_08_03T16_27_17_0700 minikube.k8s.io/version=v1.36.0 minikube.k8s.io/commit=f8f52f5de11fc6ad8244afac475e1d0f96841df1 minikube.k8s.io/name=minikube minikube.k8s.io/primary=true
I0803 16:27:17.839446   43956 ops.go:34] apiserver oom_adj: -16
I0803 16:27:17.839464   43956 kubeadm.go:1105] duration metric: took 73.903261ms to wait for elevateKubeSystemPrivileges
I0803 16:27:17.839476   43956 kubeadm.go:394] duration metric: took 8.012727678s to StartCluster
I0803 16:27:17.839489   43956 settings.go:142] acquiring lock: {Name:mk04f8b02a4296a11d28bcb5b3b13b1c897788f0 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:27:17.839552   43956 settings.go:150] Updating kubeconfig:  /home/user/.kube/config
I0803 16:27:17.840678   43956 lock.go:35] WriteFile acquiring /home/user/.kube/config: {Name:mk8216ca79fc3364ccd231ffeb919036cbe65688 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0803 16:27:17.840883   43956 start.go:235] Will wait 6m0s for node &{Name: IP:192.168.58.2 Port:8443 KubernetesVersion:v1.33.1 ContainerRuntime:docker ControlPlane:true Worker:true}
I0803 16:27:17.840944   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0803 16:27:17.840949   43956 addons.go:511] enable addons start: toEnable=map[ambassador:false amd-gpu-device-plugin:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volcano:false volumesnapshots:false yakd:false]
I0803 16:27:17.841031   43956 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0803 16:27:17.841050   43956 config.go:182] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.33.1
I0803 16:27:17.841051   43956 addons.go:238] Setting addon storage-provisioner=true in "minikube"
I0803 16:27:17.841046   43956 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0803 16:27:17.841066   43956 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0803 16:27:17.841074   43956 host.go:66] Checking if "minikube" exists ...
I0803 16:27:17.841291   43956 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0803 16:27:17.841375   43956 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0803 16:27:17.841422   43956 out.go:177] 🔎  Verifying Kubernetes components...
I0803 16:27:17.842135   43956 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0803 16:27:17.858737   43956 out.go:177]     ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0803 16:27:17.858980   43956 addons.go:238] Setting addon default-storageclass=true in "minikube"
I0803 16:27:17.858999   43956 host.go:66] Checking if "minikube" exists ...
I0803 16:27:17.859175   43956 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0803 16:27:17.859254   43956 addons.go:435] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0803 16:27:17.859264   43956 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0803 16:27:17.859304   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:17.875422   43956 addons.go:435] installing /etc/kubernetes/addons/storageclass.yaml
I0803 16:27:17.875432   43956 ssh_runner.go:362] scp storageclass/storageclass.yaml --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0803 16:27:17.875471   43956 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0803 16:27:17.875669   43956 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32773 SSHKeyPath:/home/user/.minikube/machines/minikube/id_rsa Username:docker}
I0803 16:27:17.892548   43956 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:32773 SSHKeyPath:/home/user/.minikube/machines/minikube/id_rsa Username:docker}
I0803 16:27:17.924906   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed -e '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.58.1 host.minikube.internal\n           fallthrough\n        }' -e '/^        errors *$/i \        log' | sudo /var/lib/minikube/binaries/v1.33.1/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I0803 16:27:17.984192   43956 ssh_runner.go:195] Run: sudo systemctl start kubelet
I0803 16:27:18.019150   43956 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0803 16:27:18.037260   43956 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.33.1/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0803 16:27:18.157630   43956 start.go:971] {"host.minikube.internal": 192.168.58.1} host record injected into CoreDNS's ConfigMap
I0803 16:27:18.158491   43956 api_server.go:52] waiting for apiserver process to appear ...
I0803 16:27:18.158532   43956 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0803 16:27:18.295555   43956 api_server.go:72] duration metric: took 454.648568ms to wait for apiserver process to appear ...
I0803 16:27:18.295568   43956 api_server.go:88] waiting for apiserver healthz status ...
I0803 16:27:18.295583   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:27:23.298078   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:27:23.298124   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:27:28.300007   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:27:28.300033   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:27:33.301864   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:27:33.301974   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:27:38.303577   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:27:38.303599   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:27:43.307021   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:27:43.307063   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
W0803 16:27:48.160311   43956 kapi.go:211] failed rescaling "coredns" deployment in "kube-system" namespace and "minikube" context to 1 replicas: non-retryable failure while getting "coredns" deployment scale: Get "https://192.168.58.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 192.168.58.2:8443: i/o timeout
E0803 16:27:48.160342   43956 start.go:160] Unable to scale down deployment "coredns" in namespace "kube-system" to 1 replica: non-retryable failure while getting "coredns" deployment scale: Get "https://192.168.58.2:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 192.168.58.2:8443: i/o timeout
W0803 16:27:48.296525   43956 out.go:270] ❗  Enabling 'default-storageclass' returned an error: running callbacks: [Error making standard the default storage class: Error listing StorageClasses: Get "https://192.168.58.2:8443/apis/storage.k8s.io/v1/storageclasses": dial tcp 192.168.58.2:8443: i/o timeout]
I0803 16:27:48.297508   43956 out.go:177] 🌟  Enabled addons: storage-provisioner
I0803 16:27:48.298081   43956 addons.go:514] duration metric: took 30.457146719s for enable addons: enabled=[storage-provisioner]
I0803 16:27:48.307811   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:27:48.307887   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:27:53.312030   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:27:53.312075   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:27:58.313080   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:27:58.313125   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:28:03.316996   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:28:03.317029   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:28:08.319542   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:28:08.319591   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:28:13.322982   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:28:13.323023   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:28:18.324110   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:28:18.324400   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:28:18.350806   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:28:18.350861   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:28:18.365300   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:28:18.365373   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:28:18.379365   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:28:18.379432   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:28:18.392787   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:28:18.392840   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:28:18.406464   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:28:18.406525   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:28:18.424746   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:28:18.424792   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:28:18.442111   43956 logs.go:282] 0 containers: []
W0803 16:28:18.442121   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:28:18.442128   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:28:18.442135   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:28:18.461993   43956 logs.go:123] Gathering logs for container status ...
I0803 16:28:18.462007   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:28:18.493372   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:28:18.493384   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:28:18.502280   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:28:18.502308   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:28:18.522522   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:28:18.522540   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:28:18.537377   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:28:18.537391   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:28:18.560988   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:28:18.561002   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:28:18.577897   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:28:18.577921   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:28:18.614593   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:28:18.614606   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:28:18.693847   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:28:18.693863   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:28:18.718582   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:28:18.718595   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:28:18.742090   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:28:18.742107   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:28:21.288889   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:28:26.305019   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:28:26.305156   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:28:26.326870   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:28:26.326986   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:28:26.343212   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:28:26.343270   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:28:26.358697   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:28:26.358760   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:28:26.372117   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:28:26.372187   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:28:26.384530   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:28:26.384588   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:28:26.399573   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:28:26.399624   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:28:26.414394   43956 logs.go:282] 0 containers: []
W0803 16:28:26.414407   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:28:26.414416   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:28:26.414424   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:28:26.448387   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:28:26.448399   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:28:26.458522   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:28:26.458536   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:28:26.513826   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:28:26.513836   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:28:26.534645   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:28:26.534661   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:28:26.551090   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:28:26.551104   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:28:26.565816   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:28:26.565829   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:28:26.580469   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:28:26.580482   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:28:26.593923   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:28:26.593938   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:28:26.614020   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:28:26.614034   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:28:26.630569   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:28:26.630582   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:28:26.653520   43956 logs.go:123] Gathering logs for container status ...
I0803 16:28:26.653539   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:28:29.188010   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:28:34.196110   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:28:34.196254   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:28:34.219067   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:28:34.219127   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:28:34.230833   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:28:34.230936   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:28:34.243225   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:28:34.243291   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:28:34.256485   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:28:34.256548   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:28:34.271407   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:28:34.271468   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:28:34.283039   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:28:34.283090   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:28:34.294824   43956 logs.go:282] 0 containers: []
W0803 16:28:34.294836   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:28:34.294844   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:28:34.294869   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:28:34.315943   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:28:34.315958   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:28:34.338040   43956 logs.go:123] Gathering logs for container status ...
I0803 16:28:34.338054   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:28:34.364121   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:28:34.364136   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:28:34.392985   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:28:34.393000   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:28:34.446979   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:28:34.447002   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:28:34.461889   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:28:34.461902   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:28:34.475812   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:28:34.475824   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:28:34.490447   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:28:34.490471   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:28:34.499373   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:28:34.499385   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:28:34.521531   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:28:34.521544   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:28:34.542268   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:28:34.542282   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:28:37.071628   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:28:42.092092   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:28:42.092247   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:28:42.108680   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:28:42.108764   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:28:42.121605   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:28:42.121663   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:28:42.133601   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:28:42.133657   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:28:42.146105   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:28:42.146172   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:28:42.158288   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:28:42.158344   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:28:42.170858   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:28:42.170940   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:28:42.182958   43956 logs.go:282] 0 containers: []
W0803 16:28:42.182973   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:28:42.182992   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:28:42.183003   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:28:42.192398   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:28:42.192410   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:28:42.245538   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:28:42.245555   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:28:42.262301   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:28:42.262312   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:28:42.279251   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:28:42.279266   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:28:42.298870   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:28:42.298883   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:28:42.326437   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:28:42.326452   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:28:42.349828   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:28:42.349843   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:28:42.364102   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:28:42.364115   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:28:42.384301   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:28:42.384320   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:28:42.409244   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:28:42.409255   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:28:42.425150   43956 logs.go:123] Gathering logs for container status ...
I0803 16:28:42.425166   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:28:44.962052   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:28:49.971987   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:28:49.972059   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:28:49.986025   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:28:49.986085   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:28:49.998625   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:28:49.998678   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:28:50.012832   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:28:50.012898   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:28:50.025367   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:28:50.025422   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:28:50.036897   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:28:50.036957   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:28:50.050547   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:28:50.050609   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:28:50.062834   43956 logs.go:282] 0 containers: []
W0803 16:28:50.062847   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:28:50.062855   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:28:50.062875   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:28:50.078749   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:28:50.078763   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:28:50.104211   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:28:50.104226   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:28:50.176711   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:28:50.176733   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:28:50.211819   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:28:50.211853   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:28:50.234097   43956 logs.go:123] Gathering logs for container status ...
I0803 16:28:50.234109   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:28:50.263894   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:28:50.263906   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:28:50.298419   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:28:50.298433   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:28:50.309208   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:28:50.309223   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:28:50.329617   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:28:50.329636   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:28:50.348689   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:28:50.348701   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:28:50.363053   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:28:50.363067   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:28:52.882031   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:28:57.882333   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:28:57.882502   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:28:57.907690   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:28:57.907762   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:28:57.920708   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:28:57.920762   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:28:57.931693   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:28:57.931751   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:28:57.945798   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:28:57.945850   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:28:57.958380   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:28:57.958438   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:28:57.969694   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:28:57.969802   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:28:57.982705   43956 logs.go:282] 0 containers: []
W0803 16:28:57.982715   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:28:57.982723   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:28:57.982730   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:28:57.999163   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:28:57.999175   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:28:58.020625   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:28:58.020654   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:28:58.044413   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:28:58.044424   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:28:58.063710   43956 logs.go:123] Gathering logs for container status ...
I0803 16:28:58.063725   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:28:58.089583   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:28:58.089597   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:28:58.124808   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:28:58.124828   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:28:58.136493   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:28:58.136507   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:28:58.152532   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:28:58.152562   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:28:58.168594   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:28:58.168610   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:28:58.232989   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:28:58.233002   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:28:58.255909   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:28:58.255934   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:29:00.787965   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:29:05.789305   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:29:05.789444   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:29:05.809977   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:29:05.810041   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:29:05.821684   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:29:05.821740   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:29:05.834864   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:29:05.834922   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:29:05.847458   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:29:05.847516   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:29:05.858760   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:29:05.858822   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:29:05.870811   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:29:05.870865   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:29:05.882879   43956 logs.go:282] 0 containers: []
W0803 16:29:05.882902   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:29:05.882925   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:29:05.882941   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:29:05.896503   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:29:05.896517   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:29:05.915566   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:29:05.915580   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:29:05.936102   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:29:05.936124   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:29:05.954228   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:29:05.954241   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:29:05.971966   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:29:05.971995   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:29:05.988051   43956 logs.go:123] Gathering logs for container status ...
I0803 16:29:05.988062   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:29:06.013410   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:29:06.013428   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:29:06.046400   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:29:06.046415   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:29:06.059997   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:29:06.060011   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:29:06.115690   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:29:06.115724   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:29:06.136357   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:29:06.136373   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:29:08.664034   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:29:13.669068   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:29:13.669318   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:29:13.693561   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:29:13.693628   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:29:13.705572   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:29:13.705631   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:29:13.718276   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:29:13.718330   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:29:13.730714   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:29:13.730766   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:29:13.742267   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:29:13.742361   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:29:13.754272   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:29:13.754322   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:29:13.766879   43956 logs.go:282] 0 containers: []
W0803 16:29:13.766891   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:29:13.766897   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:29:13.766906   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:29:13.820115   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:29:13.820129   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:29:13.845293   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:29:13.845306   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:29:13.869560   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:29:13.869572   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:29:13.887377   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:29:13.887392   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:29:13.903126   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:29:13.903142   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:29:13.931014   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:29:13.931028   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:29:13.946039   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:29:13.946060   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:29:13.963308   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:29:13.963325   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:29:13.978417   43956 logs.go:123] Gathering logs for container status ...
I0803 16:29:13.978432   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:29:14.010651   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:29:14.010664   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:29:14.042422   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:29:14.042437   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:29:16.564151   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:29:21.565680   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:29:21.565799   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:29:21.583595   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:29:21.583685   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:29:21.611860   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:29:21.611993   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:29:21.629363   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:29:21.629413   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:29:21.644038   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:29:21.644091   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:29:21.658903   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:29:21.658977   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:29:21.676407   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:29:21.676463   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:29:21.688797   43956 logs.go:282] 0 containers: []
W0803 16:29:21.688815   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:29:21.688826   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:29:21.688837   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:29:21.752459   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:29:21.752473   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:29:21.772297   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:29:21.772316   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:29:21.786201   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:29:21.786224   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:29:21.814097   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:29:21.814112   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:29:21.830538   43956 logs.go:123] Gathering logs for container status ...
I0803 16:29:21.830557   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:29:21.858576   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:29:21.858588   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:29:21.886875   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:29:21.886890   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:29:21.897537   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:29:21.897555   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:29:21.919657   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:29:21.919674   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:29:21.938439   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:29:21.938464   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:29:21.958823   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:29:21.958841   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:29:24.487995   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:29:29.496057   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:29:29.496229   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:29:29.515372   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:29:29.515430   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:29:29.527441   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:29:29.527497   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:29:29.540170   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:29:29.540246   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:29:29.552638   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:29:29.552697   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:29:29.564299   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:29:29.564357   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:29:29.575645   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:29:29.575699   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:29:29.587301   43956 logs.go:282] 0 containers: []
W0803 16:29:29.587325   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:29:29.587340   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:29:29.587356   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:29:29.601876   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:29:29.601891   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:29:29.615676   43956 logs.go:123] Gathering logs for container status ...
I0803 16:29:29.615689   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:29:29.644251   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:29:29.644266   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:29:29.657302   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:29:29.657318   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:29:29.676895   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:29:29.676906   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:29:29.693397   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:29:29.693410   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:29:29.707311   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:29:29.707327   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:29:29.726911   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:29:29.726926   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:29:29.748616   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:29:29.748630   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:29:29.779226   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:29:29.779240   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:29:29.833047   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:29:29.833060   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:29:32.356310   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:29:37.375135   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:29:37.375209   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:29:37.388665   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:29:37.388726   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:29:37.401205   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:29:37.401265   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:29:37.413830   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:29:37.413885   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:29:37.425564   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:29:37.425630   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:29:37.439720   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:29:37.439788   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:29:37.452096   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:29:37.452147   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:29:37.465507   43956 logs.go:282] 0 containers: []
W0803 16:29:37.465518   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:29:37.465526   43956 logs.go:123] Gathering logs for container status ...
I0803 16:29:37.465534   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:29:37.491140   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:29:37.491153   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:29:37.520462   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:29:37.520475   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:29:37.530392   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:29:37.530438   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:29:37.549075   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:29:37.549090   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:29:37.565529   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:29:37.565546   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:29:37.578815   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:29:37.578827   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:29:37.630772   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:29:37.630783   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:29:37.650258   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:29:37.650277   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:29:37.670447   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:29:37.670461   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:29:37.685130   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:29:37.685144   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:29:37.701828   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:29:37.701839   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:29:40.234057   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:29:45.247062   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:29:45.247251   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:29:45.264779   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:29:45.264834   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:29:45.277657   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:29:45.277731   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:29:45.292325   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:29:45.292384   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:29:45.304841   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:29:45.304892   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:29:45.319235   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:29:45.319294   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:29:45.331773   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:29:45.331827   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:29:45.349099   43956 logs.go:282] 0 containers: []
W0803 16:29:45.349110   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:29:45.349118   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:29:45.349127   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:29:45.363628   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:29:45.363644   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:29:45.421782   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:29:45.421799   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:29:45.441479   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:29:45.441491   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:29:45.461414   43956 logs.go:123] Gathering logs for container status ...
I0803 16:29:45.461434   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:29:45.488112   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:29:45.488126   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:29:45.514109   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:29:45.514123   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:29:45.529008   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:29:45.529027   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:29:45.548721   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:29:45.548736   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:29:45.564072   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:29:45.564085   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:29:45.578345   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:29:45.578359   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:29:45.593104   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:29:45.593117   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:29:48.116043   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:29:53.119014   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:29:53.119184   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:29:53.139234   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:29:53.139295   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:29:53.153215   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:29:53.153269   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:29:53.170763   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:29:53.170825   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:29:53.189930   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:29:53.189996   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:29:53.204340   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:29:53.204396   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:29:53.218692   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:29:53.218746   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:29:53.232677   43956 logs.go:282] 0 containers: []
W0803 16:29:53.232691   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:29:53.232700   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:29:53.232709   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:29:53.249421   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:29:53.249432   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:29:53.276195   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:29:53.276208   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:29:53.332547   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:29:53.332562   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:29:53.350054   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:29:53.350075   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:29:53.363811   43956 logs.go:123] Gathering logs for container status ...
I0803 16:29:53.363825   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:29:53.390305   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:29:53.390320   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:29:53.419927   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:29:53.419954   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:29:53.434764   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:29:53.434776   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:29:53.455235   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:29:53.455248   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:29:53.479442   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:29:53.479458   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:29:53.495320   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:29:53.495335   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:29:56.020018   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:30:01.034046   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:30:01.034194   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:30:01.055328   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:30:01.055384   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:30:01.068319   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:30:01.068389   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:30:01.084902   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:30:01.084981   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:30:01.099457   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:30:01.099513   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:30:01.114732   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:30:01.114789   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:30:01.129130   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:30:01.129186   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:30:01.142645   43956 logs.go:282] 0 containers: []
W0803 16:30:01.142655   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:30:01.142663   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:30:01.142670   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:30:01.160091   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:30:01.160104   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:30:01.185520   43956 logs.go:123] Gathering logs for container status ...
I0803 16:30:01.185536   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:30:01.211483   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:30:01.211495   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:30:01.245310   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:30:01.245323   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:30:01.266301   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:30:01.266313   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:30:01.284171   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:30:01.284203   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:30:01.298723   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:30:01.298734   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:30:01.317260   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:30:01.317270   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:30:01.332125   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:30:01.332141   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:30:01.345596   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:30:01.345610   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:30:01.415995   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:30:01.416016   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:30:03.946117   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:30:08.950178   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:30:08.950349   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:30:08.974675   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:30:08.974736   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:30:08.986557   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:30:08.986626   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:30:09.003244   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:30:09.003304   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:30:09.015557   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:30:09.015610   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:30:09.027867   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:30:09.027968   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:30:09.039443   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:30:09.039494   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:30:09.051169   43956 logs.go:282] 0 containers: []
W0803 16:30:09.051192   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:30:09.051200   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:30:09.051215   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:30:09.066103   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:30:09.066127   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:30:09.081551   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:30:09.081566   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:30:09.091932   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:30:09.091946   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:30:09.157398   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:30:09.157411   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:30:09.178391   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:30:09.178404   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:30:09.197806   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:30:09.197821   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:30:09.213554   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:30:09.213568   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:30:09.234881   43956 logs.go:123] Gathering logs for container status ...
I0803 16:30:09.234895   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:30:09.269740   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:30:09.269753   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:30:09.295197   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:30:09.295210   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:30:09.316304   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:30:09.316318   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:30:11.843082   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:30:16.854774   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:30:16.854960   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:30:16.872627   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:30:16.872680   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:30:16.884557   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:30:16.884610   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:30:16.895944   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:30:16.896011   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:30:16.909395   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:30:16.909445   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:30:16.922544   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:30:16.922606   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:30:16.935536   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:30:16.935589   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:30:16.948436   43956 logs.go:282] 0 containers: []
W0803 16:30:16.948447   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:30:16.948454   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:30:16.948462   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:30:16.966464   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:30:16.966489   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:30:16.993098   43956 logs.go:123] Gathering logs for container status ...
I0803 16:30:16.993119   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:30:17.023270   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:30:17.023283   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:30:17.051674   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:30:17.051689   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:30:17.072982   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:30:17.072995   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:30:17.094789   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:30:17.094801   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:30:17.109229   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:30:17.109240   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:30:17.123999   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:30:17.124010   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:30:17.135890   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:30:17.135904   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:30:17.197710   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:30:17.197722   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:30:17.215390   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:30:17.215404   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:30:19.735063   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:30:24.745116   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:30:24.745297   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:30:24.763886   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:30:24.763944   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:30:24.775460   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:30:24.775524   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:30:24.786907   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:30:24.787002   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:30:24.799469   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:30:24.799533   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:30:24.811730   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:30:24.811793   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:30:24.823878   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:30:24.823946   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:30:24.837423   43956 logs.go:282] 0 containers: []
W0803 16:30:24.837434   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:30:24.837441   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:30:24.837450   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:30:24.846870   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:30:24.846883   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:30:24.867013   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:30:24.867027   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:30:24.882774   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:30:24.882789   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:30:24.896394   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:30:24.896406   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:30:24.923121   43956 logs.go:123] Gathering logs for container status ...
I0803 16:30:24.923133   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:30:24.954689   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:30:24.954703   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:30:24.983931   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:30:24.983943   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:30:25.043645   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:30:25.043659   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:30:25.060369   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:30:25.060380   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:30:25.078871   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:30:25.078886   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:30:25.097475   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:30:25.097488   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:30:27.613102   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:30:32.613789   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:30:32.613946   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:30:32.638347   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:30:32.638415   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:30:32.652796   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:30:32.652950   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:30:32.667295   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:30:32.667351   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:30:32.681497   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:30:32.681556   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:30:32.694567   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:30:32.694627   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:30:32.709362   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:30:32.709419   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:30:32.725372   43956 logs.go:282] 0 containers: []
W0803 16:30:32.725390   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:30:32.725400   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:30:32.725412   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:30:32.735095   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:30:32.735108   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:30:32.796880   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:30:32.796894   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:30:32.822575   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:30:32.822599   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:30:32.845822   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:30:32.845834   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:30:32.865140   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:30:32.865156   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:30:32.885255   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:30:32.885286   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:30:32.902713   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:30:32.902726   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:30:32.947238   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:30:32.947278   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:30:32.981425   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:30:32.981441   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:30:33.008453   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:30:33.008494   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:30:33.029287   43956 logs.go:123] Gathering logs for container status ...
I0803 16:30:33.029303   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:30:35.560319   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:30:40.572994   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:30:40.573092   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:30:40.593311   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:30:40.593380   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:30:40.614483   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:30:40.614554   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:30:40.634612   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:30:40.634873   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:30:40.655267   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:30:40.655330   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:30:40.674144   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:30:40.674205   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:30:40.691075   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:30:40.691146   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:30:40.710395   43956 logs.go:282] 0 containers: []
W0803 16:30:40.710410   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:30:40.710418   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:30:40.710433   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:30:40.737400   43956 logs.go:123] Gathering logs for container status ...
I0803 16:30:40.737422   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:30:40.778633   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:30:40.778646   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:30:40.811853   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:30:40.811866   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:30:40.824882   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:30:40.824893   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:30:40.847496   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:30:40.847509   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:30:40.871108   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:30:40.871118   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:30:40.886095   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:30:40.886117   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:30:40.905445   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:30:40.905467   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:30:40.937559   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:30:40.937576   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:30:40.952181   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:30:40.952197   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:30:41.027716   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:30:41.027725   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:30:43.551107   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:30:48.554003   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:30:48.554105   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:30:48.571434   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:30:48.571487   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:30:48.591457   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:30:48.591535   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:30:48.607299   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:30:48.607354   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:30:48.627892   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:30:48.627961   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:30:48.647928   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:30:48.648019   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:30:48.665220   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:30:48.665297   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:30:48.683319   43956 logs.go:282] 0 containers: []
W0803 16:30:48.683330   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:30:48.683337   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:30:48.683345   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:30:48.703952   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:30:48.703963   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:30:48.729803   43956 logs.go:123] Gathering logs for container status ...
I0803 16:30:48.729818   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:30:48.766513   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:30:48.766526   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:30:48.777417   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:30:48.777432   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:30:48.806267   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:30:48.806284   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:30:48.825029   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:30:48.825041   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:30:48.843191   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:30:48.843205   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:30:48.886501   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:30:48.886524   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:30:48.962148   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:30:48.962164   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:30:48.984884   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:30:48.984910   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:30:49.002924   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:30:49.002938   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:30:51.527857   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:30:56.548109   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:30:56.548250   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:30:56.570095   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:30:56.570147   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:30:56.585063   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:30:56.585127   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:30:56.598237   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:30:56.598287   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:30:56.610953   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:30:56.611050   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:30:56.622367   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:30:56.622424   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:30:56.634724   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:30:56.634780   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:30:56.649412   43956 logs.go:282] 0 containers: []
W0803 16:30:56.649424   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:30:56.649432   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:30:56.649440   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:30:56.691164   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:30:56.691178   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:30:56.702600   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:30:56.702615   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:30:56.763882   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:30:56.763897   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:30:56.781984   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:30:56.781996   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:30:56.797200   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:30:56.797216   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:30:56.815548   43956 logs.go:123] Gathering logs for container status ...
I0803 16:30:56.815562   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:30:56.840973   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:30:56.840988   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:30:56.865498   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:30:56.865511   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:30:56.886160   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:30:56.886170   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:30:56.903508   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:30:56.903521   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:30:56.927509   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:30:56.927533   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:30:59.451041   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:31:04.460011   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:31:04.460086   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:31:04.474789   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:31:04.474842   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:31:04.486711   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:31:04.486809   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:31:04.498905   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:31:04.498989   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:31:04.511220   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:31:04.511280   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:31:04.523949   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:31:04.524031   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:31:04.537715   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:31:04.537771   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:31:04.552750   43956 logs.go:282] 0 containers: []
W0803 16:31:04.552761   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:31:04.552769   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:31:04.552778   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:31:04.565560   43956 logs.go:123] Gathering logs for container status ...
I0803 16:31:04.565571   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:31:04.591408   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:31:04.591421   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:31:04.624261   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:31:04.624274   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:31:04.688257   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:31:04.688271   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:31:04.706497   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:31:04.706515   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:31:04.720573   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:31:04.720588   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:31:04.738421   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:31:04.738433   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:31:04.749205   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:31:04.749217   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:31:04.766500   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:31:04.766513   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:31:04.781476   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:31:04.781489   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:31:04.798000   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:31:04.798013   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:31:07.336069   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:31:12.358033   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:31:12.358146   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0803 16:31:12.375597   43956 logs.go:282] 1 containers: [3aca61c3200b]
I0803 16:31:12.375663   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0803 16:31:12.389681   43956 logs.go:282] 1 containers: [4fb45d21e13a]
I0803 16:31:12.389752   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0803 16:31:12.401359   43956 logs.go:282] 2 containers: [92f64bfa404f 55d7cc3eba8f]
I0803 16:31:12.401421   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0803 16:31:12.415651   43956 logs.go:282] 1 containers: [dce08fd179a8]
I0803 16:31:12.415720   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0803 16:31:12.431027   43956 logs.go:282] 1 containers: [65b0940d0a7b]
I0803 16:31:12.431081   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0803 16:31:12.445417   43956 logs.go:282] 1 containers: [e41e6b144155]
I0803 16:31:12.445471   43956 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0803 16:31:12.460521   43956 logs.go:282] 0 containers: []
W0803 16:31:12.460532   43956 logs.go:284] No container was found matching "kindnet"
I0803 16:31:12.460540   43956 logs.go:123] Gathering logs for describe nodes ...
I0803 16:31:12.460547   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.33.1/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0803 16:31:12.518868   43956 logs.go:123] Gathering logs for container status ...
I0803 16:31:12.518894   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0803 16:31:12.547939   43956 logs.go:123] Gathering logs for kube-apiserver [3aca61c3200b] ...
I0803 16:31:12.547956   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3aca61c3200b"
I0803 16:31:12.569827   43956 logs.go:123] Gathering logs for etcd [4fb45d21e13a] ...
I0803 16:31:12.569841   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 4fb45d21e13a"
I0803 16:31:12.588287   43956 logs.go:123] Gathering logs for coredns [92f64bfa404f] ...
I0803 16:31:12.588301   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f64bfa404f"
I0803 16:31:12.602298   43956 logs.go:123] Gathering logs for coredns [55d7cc3eba8f] ...
I0803 16:31:12.602311   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 55d7cc3eba8f"
I0803 16:31:12.616770   43956 logs.go:123] Gathering logs for kube-scheduler [dce08fd179a8] ...
I0803 16:31:12.616783   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 dce08fd179a8"
I0803 16:31:12.637808   43956 logs.go:123] Gathering logs for kube-proxy [65b0940d0a7b] ...
I0803 16:31:12.637825   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 65b0940d0a7b"
I0803 16:31:12.652778   43956 logs.go:123] Gathering logs for kube-controller-manager [e41e6b144155] ...
I0803 16:31:12.652801   43956 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 e41e6b144155"
I0803 16:31:12.674294   43956 logs.go:123] Gathering logs for Docker ...
I0803 16:31:12.674309   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0803 16:31:12.690946   43956 logs.go:123] Gathering logs for kubelet ...
I0803 16:31:12.690960   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0803 16:31:12.724883   43956 logs.go:123] Gathering logs for dmesg ...
I0803 16:31:12.724897   43956 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0803 16:31:15.246104   43956 api_server.go:253] Checking apiserver healthz at https://192.168.58.2:8443/healthz ...
I0803 16:31:20.256000   43956 api_server.go:269] stopped: https://192.168.58.2:8443/healthz: Get "https://192.168.58.2:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0803 16:31:20.258733   43956 out.go:201] 
W0803 16:31:20.259610   43956 out.go:270] ❌  Exiting due to GUEST_START: failed to start node: wait 6m0s for node: wait for healthy API server: apiserver healthz never reported healthy: context deadline exceeded
W0803 16:31:20.259641   43956 out.go:270] 
W0803 16:31:20.262244   43956 out.go:293] [31m╭───────────────────────────────────────────────────────────────────────────────────────────╮[0m
[31m│[0m                                                                                           [31m│[0m
[31m│[0m    😿  If the above advice does not help, please let us know:                             [31m│[0m
[31m│[0m    👉  https://github.com/kubernetes/minikube/issues/new/choose                           [31m│[0m
[31m│[0m                                                                                           [31m│[0m
[31m│[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31m│[0m
[31m│[0m                                                                                           [31m│[0m
[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯[0m
I0803 16:31:20.263016   43956 out.go:201] 


==> Docker <==
Aug 03 14:27:04 minikube dockerd[629]: time="2025-08-03T14:27:04.453478316Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Aug 03 14:27:04 minikube dockerd[629]: time="2025-08-03T14:27:04.453503112Z" level=info msg="Daemon shutdown complete"
Aug 03 14:27:04 minikube systemd[1]: docker.service: Deactivated successfully.
Aug 03 14:27:04 minikube systemd[1]: Stopped Docker Application Container Engine.
Aug 03 14:27:04 minikube systemd[1]: Starting Docker Application Container Engine...
Aug 03 14:27:04 minikube dockerd[963]: time="2025-08-03T14:27:04.562644826Z" level=info msg="Starting up"
Aug 03 14:27:04 minikube dockerd[963]: time="2025-08-03T14:27:04.563939526Z" level=info msg="OTEL tracing is not configured, using no-op tracer provider"
Aug 03 14:27:04 minikube dockerd[963]: time="2025-08-03T14:27:04.572216330Z" level=info msg="Creating a containerd client" address=/run/containerd/containerd.sock timeout=1m0s
Aug 03 14:27:04 minikube dockerd[963]: time="2025-08-03T14:27:04.585132583Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Aug 03 14:27:04 minikube dockerd[963]: time="2025-08-03T14:27:04.589495014Z" level=info msg="Loading containers: start."
Aug 03 14:27:04 minikube dockerd[963]: time="2025-08-03T14:27:04.849239634Z" level=info msg="Processing signal 'terminated'"
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.254026374Z" level=warning msg="Error (Unable to complete atomic operation, key modified) deleting object [endpoint_count f974bc804ece2ac4121adb33b509abf62f966a9d74c8595ab0efdd57495a05e3], retrying...."
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.280120618Z" level=info msg="Loading containers: done."
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.289291878Z" level=info msg="Docker daemon" commit=01f442b containerd-snapshotter=false storage-driver=overlay2 version=28.1.1
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.289500803Z" level=info msg="Initializing buildkit"
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.309346190Z" level=info msg="Completed buildkit initialization"
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.315485057Z" level=info msg="Daemon has completed initialization"
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.315540625Z" level=info msg="API listen on /var/run/docker.sock"
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.315638325Z" level=info msg="API listen on [::]:2376"
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.316237351Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Aug 03 14:27:06 minikube dockerd[963]: time="2025-08-03T14:27:06.316583145Z" level=info msg="Daemon shutdown complete"
Aug 03 14:27:06 minikube systemd[1]: docker.service: Deactivated successfully.
Aug 03 14:27:06 minikube systemd[1]: Stopped Docker Application Container Engine.
Aug 03 14:27:06 minikube systemd[1]: Starting Docker Application Container Engine...
Aug 03 14:27:06 minikube dockerd[1259]: time="2025-08-03T14:27:06.369747200Z" level=info msg="Starting up"
Aug 03 14:27:06 minikube dockerd[1259]: time="2025-08-03T14:27:06.370838930Z" level=info msg="OTEL tracing is not configured, using no-op tracer provider"
Aug 03 14:27:06 minikube dockerd[1259]: time="2025-08-03T14:27:06.376215681Z" level=info msg="Creating a containerd client" address=/run/containerd/containerd.sock timeout=1m0s
Aug 03 14:27:06 minikube dockerd[1259]: time="2025-08-03T14:27:06.380932921Z" level=info msg="[graphdriver] trying configured driver: overlay2"
Aug 03 14:27:06 minikube dockerd[1259]: time="2025-08-03T14:27:06.441106870Z" level=info msg="Loading containers: start."
Aug 03 14:27:08 minikube dockerd[1259]: time="2025-08-03T14:27:08.192672428Z" level=warning msg="Error (Unable to complete atomic operation, key modified) deleting object [endpoint_count da6e0a17ae158f76c4abedf80357350fda07ef024a1dd5643be458469d20f0b1], retrying...."
Aug 03 14:27:08 minikube dockerd[1259]: time="2025-08-03T14:27:08.223574175Z" level=info msg="Loading containers: done."
Aug 03 14:27:08 minikube dockerd[1259]: time="2025-08-03T14:27:08.232293081Z" level=info msg="Docker daemon" commit=01f442b containerd-snapshotter=false storage-driver=overlay2 version=28.1.1
Aug 03 14:27:08 minikube dockerd[1259]: time="2025-08-03T14:27:08.232334028Z" level=info msg="Initializing buildkit"
Aug 03 14:27:08 minikube dockerd[1259]: time="2025-08-03T14:27:08.248951913Z" level=info msg="Completed buildkit initialization"
Aug 03 14:27:08 minikube dockerd[1259]: time="2025-08-03T14:27:08.253664267Z" level=info msg="Daemon has completed initialization"
Aug 03 14:27:08 minikube dockerd[1259]: time="2025-08-03T14:27:08.253790795Z" level=info msg="API listen on [::]:2376"
Aug 03 14:27:08 minikube dockerd[1259]: time="2025-08-03T14:27:08.253814494Z" level=info msg="API listen on /var/run/docker.sock"
Aug 03 14:27:08 minikube systemd[1]: Started Docker Application Container Engine.
Aug 03 14:27:08 minikube systemd[1]: Starting CRI Interface for Docker Application Container Engine...
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Starting cri-dockerd dev (HEAD)"
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Connecting to docker on the Endpoint unix:///var/run/docker.sock"
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Start docker client with request timeout 0s"
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Hairpin mode is set to hairpin-veth"
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Loaded network plugin cni"
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Docker cri networking managed by network plugin cni"
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Setting cgroupDriver systemd"
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:,},}"
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Starting the GRPC backend for the Docker CRI interface."
Aug 03 14:27:08 minikube cri-dockerd[1557]: time="2025-08-03T14:27:08Z" level=info msg="Start cri-dockerd grpc backend"
Aug 03 14:27:08 minikube systemd[1]: Started CRI Interface for Docker Application Container Engine.
Aug 03 14:27:12 minikube cri-dockerd[1557]: time="2025-08-03T14:27:12Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/eae5b1403fc6b206d7279aaacb487bc4ce83fe94fb90af07f8ea10301dd55b20/resolv.conf as [nameserver 192.168.5.2 options ndots:0]"
Aug 03 14:27:12 minikube cri-dockerd[1557]: time="2025-08-03T14:27:12Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/3211573c5382a99b8818fdb82e0bdbdd17c6c18102405c15885be070c0baa6fc/resolv.conf as [nameserver 192.168.5.2 options ndots:0]"
Aug 03 14:27:12 minikube cri-dockerd[1557]: time="2025-08-03T14:27:12Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/52469ee0e2314941b370be1aeb81306b9fa4884a197784f1ad7c3eca6d1cf8c0/resolv.conf as [nameserver 192.168.5.2 options ndots:0]"
Aug 03 14:27:12 minikube cri-dockerd[1557]: time="2025-08-03T14:27:12Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/e55b64c5a1f01f7e276bc642c768a8d3f165078250cf6083e5c7ace03b41da19/resolv.conf as [nameserver 192.168.5.2 options ndots:0]"
Aug 03 14:27:22 minikube cri-dockerd[1557]: time="2025-08-03T14:27:22Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/a4f2add155d925a7e102dba2335944bdb49a532bb1645a3e839ee3dd1f87d21a/resolv.conf as [nameserver 192.168.5.2 options ndots:0]"
Aug 03 14:27:22 minikube cri-dockerd[1557]: time="2025-08-03T14:27:22Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/d134401bc0050edc2432d54b0c130cb86f43566dc25df3af033d6a9daa91805c/resolv.conf as [nameserver 192.168.5.2 options ndots:0]"
Aug 03 14:27:22 minikube cri-dockerd[1557]: time="2025-08-03T14:27:22Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/ffbb834df710365a5284fa1c73cbbfb7999947254d0414aba5a43398e242cf55/resolv.conf as [nameserver 192.168.5.2 options ndots:0]"
Aug 03 14:27:22 minikube cri-dockerd[1557]: time="2025-08-03T14:27:22Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/a9936dc00d22ff1a2714579d55abc03dfd55d136f60266642354ca134f8663c8/resolv.conf as [nameserver 192.168.5.2 options ndots:0]"
Aug 03 14:27:27 minikube cri-dockerd[1557]: time="2025-08-03T14:27:27Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:10.244.0.0/24,},}"
Aug 03 14:27:52 minikube dockerd[1259]: time="2025-08-03T14:27:52.495852337Z" level=info msg="ignoring event" container=2f02e615249f809ff067127678609798a23a56477c2b9a07642027e66b1ff18a module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"


==> container status <==
CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
1e6e76495a9c8       6e38f40d628db       5 minutes ago       Running             storage-provisioner       1                   a4f2add155d92       storage-provisioner
92f64bfa404f8       1cf5f116067c6       6 minutes ago       Running             coredns                   0                   a9936dc00d22f       coredns-674b8bbfcf-tdcd5
55d7cc3eba8f9       1cf5f116067c6       6 minutes ago       Running             coredns                   0                   ffbb834df7103       coredns-674b8bbfcf-wqkrt
65b0940d0a7b0       b79c189b052cd       6 minutes ago       Running             kube-proxy                0                   d134401bc0050       kube-proxy-nnzdq
2f02e615249f8       6e38f40d628db       6 minutes ago       Exited              storage-provisioner       0                   a4f2add155d92       storage-provisioner
4fb45d21e13ab       499038711c081       6 minutes ago       Running             etcd                      0                   e55b64c5a1f01       etcd-minikube
dce08fd179a83       398c985c0d950       6 minutes ago       Running             kube-scheduler            0                   52469ee0e2314       kube-scheduler-minikube
3aca61c3200bd       c6ab243b29f82       6 minutes ago       Running             kube-apiserver            0                   3211573c5382a       kube-apiserver-minikube
e41e6b1441550       ef43894fa110c       6 minutes ago       Running             kube-controller-manager   0                   eae5b1403fc6b       kube-controller-manager-minikube


==> coredns [55d7cc3eba8f] <==
maxprocs: Leaving GOMAXPROCS=2: CPU quota undefined
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 4440e7469c6be8c359d7b298db58524fed56dc1669734a56c9c4c387cf0e3c2da951c3e208d1d199d29de038fba78e514eb90088d28e87a2d2e4287d9ee777cc
CoreDNS-1.12.0
linux/amd64, go1.23.3, 51e11f1
[INFO] 127.0.0.1:56552 - 3115 "HINFO IN 5096268850052455007.4973714699285457914. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.035774904s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.31.2/tools/cache/reflector.go:243: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: Unhandled Error
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.31.2/tools/cache/reflector.go:243: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: Unhandled Error
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.31.2/tools/cache/reflector.go:243: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: Unhandled Error


==> coredns [92f64bfa404f] <==
maxprocs: Leaving GOMAXPROCS=2: CPU quota undefined
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[WARNING] plugin/kubernetes: starting server with unsynced Kubernetes API
.:53
[INFO] plugin/reload: Running configuration SHA512 = 4440e7469c6be8c359d7b298db58524fed56dc1669734a56c9c4c387cf0e3c2da951c3e208d1d199d29de038fba78e514eb90088d28e87a2d2e4287d9ee777cc
CoreDNS-1.12.0
linux/amd64, go1.23.3, 51e11f1
[INFO] 127.0.0.1:46577 - 49649 "HINFO IN 5148781665969344071.7574819029833792996. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.034901236s
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/ready: Still waiting on: "kubernetes"
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.31.2/tools/cache/reflector.go:243: failed to list *v1.Namespace: Get "https://10.96.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.31.2/tools/cache/reflector.go:243: failed to list *v1.Service: Get "https://10.96.0.1:443/api/v1/services?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: Unhandled Error
[ERROR] plugin/kubernetes: Unhandled Error
[INFO] plugin/kubernetes: pkg/mod/k8s.io/client-go@v0.31.2/tools/cache/reflector.go:243: failed to list *v1.EndpointSlice: Get "https://10.96.0.1:443/apis/discovery.k8s.io/v1/endpointslices?limit=500&resourceVersion=0": dial tcp 10.96.0.1:443: i/o timeout
[ERROR] plugin/kubernetes: Unhandled Error


==> describe nodes <==
Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=f8f52f5de11fc6ad8244afac475e1d0f96841df1
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2025_08_03T16_27_17_0700
                    minikube.k8s.io/version=v1.36.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Sun, 03 Aug 2025 14:27:14 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Sun, 03 Aug 2025 14:33:44 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Sun, 03 Aug 2025 14:32:33 +0000   Sun, 03 Aug 2025 14:27:13 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Sun, 03 Aug 2025 14:32:33 +0000   Sun, 03 Aug 2025 14:27:13 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Sun, 03 Aug 2025 14:32:33 +0000   Sun, 03 Aug 2025 14:27:13 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Sun, 03 Aug 2025 14:32:33 +0000   Sun, 03 Aug 2025 14:27:14 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.58.2
  Hostname:    minikube
Capacity:
  cpu:                2
  ephemeral-storage:  102625208Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             6074616Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  102625208Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             6074616Ki
  pods:               110
System Info:
  Machine ID:                 a5eeb17a04d24482838b0abc6434215b
  System UUID:                a5eeb17a04d24482838b0abc6434215b
  Boot ID:                    8e48d464-2c26-44c0-9ef8-ac1dfc3c8cca
  Kernel Version:             6.6.93-0-virt
  OS Image:                   Ubuntu 22.04.5 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://28.1.1
  Kubelet Version:            v1.33.1
  Kube-Proxy Version:         
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (8 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  kube-system                 coredns-674b8bbfcf-tdcd5            100m (5%)     0 (0%)      70Mi (1%)        170Mi (2%)     6m29s
  kube-system                 coredns-674b8bbfcf-wqkrt            100m (5%)     0 (0%)      70Mi (1%)        170Mi (2%)     6m29s
  kube-system                 etcd-minikube                       100m (5%)     0 (0%)      100Mi (1%)       0 (0%)         6m35s
  kube-system                 kube-apiserver-minikube             250m (12%)    0 (0%)      0 (0%)           0 (0%)         6m35s
  kube-system                 kube-controller-manager-minikube    200m (10%)    0 (0%)      0 (0%)           0 (0%)         6m35s
  kube-system                 kube-proxy-nnzdq                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m29s
  kube-system                 kube-scheduler-minikube             100m (5%)     0 (0%)      0 (0%)           0 (0%)         6m35s
  kube-system                 storage-provisioner                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         6m34s
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (42%)  0 (0%)
  memory             240Mi (4%)  340Mi (5%)
  ephemeral-storage  0 (0%)      0 (0%)
  hugepages-1Gi      0 (0%)      0 (0%)
  hugepages-2Mi      0 (0%)      0 (0%)
Events:
  Type    Reason                   Age                    From             Message
  ----    ------                   ----                   ----             -------
  Normal  Starting                 6m28s                  kube-proxy       
  Normal  Starting                 6m40s                  kubelet          Starting kubelet.
  Normal  NodeHasSufficientMemory  6m39s (x8 over 6m40s)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    6m39s (x8 over 6m40s)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     6m39s (x7 over 6m40s)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeAllocatableEnforced  6m39s                  kubelet          Updated Node Allocatable limit across pods
  Normal  Starting                 6m35s                  kubelet          Starting kubelet.
  Normal  NodeAllocatableEnforced  6m35s                  kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  6m35s                  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    6m35s                  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     6m35s                  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  RegisteredNode           6m30s                  node-controller  Node minikube event: Registered Node minikube in Controller


==> dmesg <==
[Aug 3 14:17] ----------------
[  +0.000000] | NMI testsuite:
[  +0.000000] --------------------
[  +0.000000]   remote IPI:  ok  |
[  +0.000000]    local IPI:  ok  |
[  +0.000000] --------------------
[  +0.000000] Good, all   2 testcases passed! |
[  +0.000000] ---------------------------------
[  +0.539893] Alpine Init 3.11.1-r0
[  +0.000412] Loading boot drivers...
[  +0.078943] Loading boot drivers: ok.
[  +0.003154] Mounting boot media...
[  +0.069683] sr 6:0:0:0: Power-on or device reset occurred
[  +0.224932] block sr0: the capability attribute has been deprecated.
[  +0.082353] Mounting boot media: ok.
[  +0.001894] Loading user settings from /media/sr0/alpine.apkovl.tar.gz...
[  +1.310479] Loading user settings from /media/sr0/alpine.apkovl.tar.gz: ok.
[  +0.011586] Installing packages to root filesystem...
[Aug 3 14:18] Installing packages to root filesystem: ok.
[  +0.490723] squashfs: Unknown parameter 'mode'
[ +40.004182] kauditd_printk_skb: 191 callbacks suppressed
[  +5.652865] kauditd_printk_skb: 468 callbacks suppressed
[Aug 3 14:20] kauditd_printk_skb: 291 callbacks suppressed
[Aug 3 14:26] kauditd_printk_skb: 100 callbacks suppressed
[  +5.041738] kauditd_printk_skb: 195 callbacks suppressed
[Aug 3 14:27] systemd[9389]: memfd_create() called without MFD_EXEC or MFD_NOEXEC_SEAL set
[  +0.897744] kauditd_printk_skb: 330 callbacks suppressed
[  +5.013612] kauditd_printk_skb: 801 callbacks suppressed
[  +5.354369] kauditd_printk_skb: 685 callbacks suppressed
[  +5.058496] kauditd_printk_skb: 408 callbacks suppressed
[  +5.006369] kauditd_printk_skb: 113 callbacks suppressed
[ +29.745950] kauditd_printk_skb: 275 callbacks suppressed
[Aug 3 14:28] kauditd_printk_skb: 22 callbacks suppressed
[ +24.999596] kauditd_printk_skb: 22 callbacks suppressed
[  +7.923559] kauditd_printk_skb: 20 callbacks suppressed
[  +7.843129] kauditd_printk_skb: 20 callbacks suppressed
[  +7.922972] kauditd_printk_skb: 30 callbacks suppressed
[  +7.940861] kauditd_printk_skb: 20 callbacks suppressed
[Aug 3 14:29] kauditd_printk_skb: 20 callbacks suppressed
[  +7.883622] kauditd_printk_skb: 20 callbacks suppressed
[  +7.922843] kauditd_printk_skb: 20 callbacks suppressed
[  +7.912478] kauditd_printk_skb: 20 callbacks suppressed
[  +7.865139] kauditd_printk_skb: 20 callbacks suppressed
[  +7.881868] kauditd_printk_skb: 20 callbacks suppressed
[  +7.929012] kauditd_printk_skb: 20 callbacks suppressed
[Aug 3 14:30] kauditd_printk_skb: 20 callbacks suppressed
[  +7.879338] kauditd_printk_skb: 20 callbacks suppressed
[  +7.928269] kauditd_printk_skb: 20 callbacks suppressed
[  +7.842628] kauditd_printk_skb: 20 callbacks suppressed
[  +7.888481] kauditd_printk_skb: 20 callbacks suppressed
[  +8.014430] kauditd_printk_skb: 20 callbacks suppressed
[  +7.993127] kauditd_printk_skb: 20 callbacks suppressed
[  +7.917360] kauditd_printk_skb: 20 callbacks suppressed
[Aug 3 14:31] kauditd_printk_skb: 20 callbacks suppressed
[  +7.907712] kauditd_printk_skb: 20 callbacks suppressed
[Aug 3 14:33] kauditd_printk_skb: 20 callbacks suppressed


==> etcd [4fb45d21e13a] <==
{"level":"warn","ts":"2025-08-03T14:27:13.159636Z","caller":"embed/config.go:689","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"warn","ts":"2025-08-03T14:27:13.159762Z","caller":"etcdmain/config.go:389","msg":"--proxy-refresh-interval is deprecated in 3.5 and will be decommissioned in 3.6."}
{"level":"info","ts":"2025-08-03T14:27:13.159776Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.58.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://192.168.58.2:2380","--initial-cluster=minikube=https://192.168.58.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.58.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.58.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"warn","ts":"2025-08-03T14:27:13.159835Z","caller":"embed/config.go:689","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2025-08-03T14:27:13.159850Z","caller":"embed/etcd.go:140","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.58.2:2380"]}
{"level":"info","ts":"2025-08-03T14:27:13.159874Z","caller":"embed/etcd.go:528","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2025-08-03T14:27:13.160202Z","caller":"embed/etcd.go:148","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.58.2:2379"]}
{"level":"info","ts":"2025-08-03T14:27:13.160318Z","caller":"embed/etcd.go:323","msg":"starting an etcd server","etcd-version":"3.5.21","git-sha":"a17edfd","go-version":"go1.23.7","go-os":"linux","go-arch":"amd64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":false,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.58.2:2380"],"listen-peer-urls":["https://192.168.58.2:2380"],"advertise-client-urls":["https://192.168.58.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.58.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"minikube=https://192.168.58.2:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2025-08-03T14:27:13.162757Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"2.25785ms"}
{"level":"info","ts":"2025-08-03T14:27:13.169740Z","caller":"etcdserver/raft.go:506","msg":"starting local member","local-member-id":"b2c6679ac05f2cf1","cluster-id":"3a56e4ca95e2355c"}
{"level":"info","ts":"2025-08-03T14:27:13.169928Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 switched to configuration voters=()"}
{"level":"info","ts":"2025-08-03T14:27:13.169961Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 became follower at term 0"}
{"level":"info","ts":"2025-08-03T14:27:13.169977Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft b2c6679ac05f2cf1 [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2025-08-03T14:27:13.170001Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 became follower at term 1"}
{"level":"info","ts":"2025-08-03T14:27:13.170028Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 switched to configuration voters=(12882097698489969905)"}
{"level":"warn","ts":"2025-08-03T14:27:13.176775Z","caller":"auth/store.go:1241","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2025-08-03T14:27:13.177687Z","caller":"mvcc/kvstore.go:425","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2025-08-03T14:27:13.177747Z","caller":"etcdserver/server.go:628","msg":"restore consistentIndex","index":0}
{"level":"info","ts":"2025-08-03T14:27:13.178357Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2025-08-03T14:27:13.179574Z","caller":"etcdserver/server.go:875","msg":"starting etcd server","local-member-id":"b2c6679ac05f2cf1","local-server-version":"3.5.21","cluster-version":"to_be_decided"}
{"level":"info","ts":"2025-08-03T14:27:13.184470Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2025-08-03T14:27:13.184584Z","caller":"etcdserver/server.go:759","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"b2c6679ac05f2cf1","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2025-08-03T14:27:13.184646Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2025-08-03T14:27:13.184838Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2025-08-03T14:27:13.184850Z","caller":"fileutil/purge.go:50","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2025-08-03T14:27:13.185022Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 switched to configuration voters=(12882097698489969905)"}
{"level":"info","ts":"2025-08-03T14:27:13.185076Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"3a56e4ca95e2355c","local-member-id":"b2c6679ac05f2cf1","added-peer-id":"b2c6679ac05f2cf1","added-peer-peer-urls":["https://192.168.58.2:2380"],"added-peer-is-learner":false}
{"level":"info","ts":"2025-08-03T14:27:13.193972Z","caller":"embed/etcd.go:762","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2025-08-03T14:27:13.194072Z","caller":"embed/etcd.go:633","msg":"serving peer traffic","address":"192.168.58.2:2380"}
{"level":"info","ts":"2025-08-03T14:27:13.194161Z","caller":"embed/etcd.go:603","msg":"cmux::serve","address":"192.168.58.2:2380"}
{"level":"info","ts":"2025-08-03T14:27:13.194520Z","caller":"embed/etcd.go:292","msg":"now serving peer/client/metrics","local-member-id":"b2c6679ac05f2cf1","initial-advertise-peer-urls":["https://192.168.58.2:2380"],"listen-peer-urls":["https://192.168.58.2:2380"],"advertise-client-urls":["https://192.168.58.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.58.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2025-08-03T14:27:13.194559Z","caller":"embed/etcd.go:908","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2025-08-03T14:27:13.670457Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 is starting a new election at term 1"}
{"level":"info","ts":"2025-08-03T14:27:13.670594Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 became pre-candidate at term 1"}
{"level":"info","ts":"2025-08-03T14:27:13.670668Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 received MsgPreVoteResp from b2c6679ac05f2cf1 at term 1"}
{"level":"info","ts":"2025-08-03T14:27:13.670703Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 became candidate at term 2"}
{"level":"info","ts":"2025-08-03T14:27:13.670761Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 received MsgVoteResp from b2c6679ac05f2cf1 at term 2"}
{"level":"info","ts":"2025-08-03T14:27:13.670789Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"b2c6679ac05f2cf1 became leader at term 2"}
{"level":"info","ts":"2025-08-03T14:27:13.670806Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: b2c6679ac05f2cf1 elected leader b2c6679ac05f2cf1 at term 2"}
{"level":"info","ts":"2025-08-03T14:27:13.704054Z","caller":"etcdserver/server.go:2144","msg":"published local member to cluster through raft","local-member-id":"b2c6679ac05f2cf1","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.58.2:2379]}","request-path":"/0/members/b2c6679ac05f2cf1/attributes","cluster-id":"3a56e4ca95e2355c","publish-timeout":"7s"}
{"level":"info","ts":"2025-08-03T14:27:13.704339Z","caller":"embed/serve.go:124","msg":"ready to serve client requests"}
{"level":"info","ts":"2025-08-03T14:27:13.704348Z","caller":"embed/serve.go:124","msg":"ready to serve client requests"}
{"level":"info","ts":"2025-08-03T14:27:13.704376Z","caller":"etcdserver/server.go:2697","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2025-08-03T14:27:13.704415Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2025-08-03T14:27:13.704841Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2025-08-03T14:27:13.705098Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2025-08-03T14:27:13.705379Z","caller":"v3rpc/health.go:61","msg":"grpc service status changed","service":"","status":"SERVING"}
{"level":"info","ts":"2025-08-03T14:27:13.706015Z","caller":"embed/serve.go:275","msg":"serving client traffic securely","traffic":"grpc+http","address":"127.0.0.1:2379"}
{"level":"info","ts":"2025-08-03T14:27:13.706117Z","caller":"membership/cluster.go:587","msg":"set initial cluster version","cluster-id":"3a56e4ca95e2355c","local-member-id":"b2c6679ac05f2cf1","cluster-version":"3.5"}
{"level":"info","ts":"2025-08-03T14:27:13.706351Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2025-08-03T14:27:13.706490Z","caller":"etcdserver/server.go:2721","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2025-08-03T14:27:13.705980Z","caller":"embed/serve.go:275","msg":"serving client traffic securely","traffic":"grpc+http","address":"192.168.58.2:2379"}


==> kernel <==
 14:33:51 up 15 min,  0 users,  load average: 0.46, 0.46, 0.28
Linux minikube 6.6.93-0-virt #1-Alpine SMP PREEMPT_DYNAMIC 2025-06-09 11:51:57 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.5 LTS"


==> kube-apiserver [3aca61c3200b] <==
I0803 14:27:14.338985       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0803 14:27:14.339027       1 repairip.go:200] Starting ipallocator-repair-controller
I0803 14:27:14.339032       1 shared_informer.go:350] "Waiting for caches to sync" controller="ipallocator-repair-controller"
I0803 14:27:14.339178       1 default_servicecidr_controller.go:110] Starting kubernetes-service-cidr-controller
I0803 14:27:14.339185       1 shared_informer.go:350] "Waiting for caches to sync" controller="kubernetes-service-cidr-controller"
I0803 14:27:14.340756       1 crdregistration_controller.go:114] Starting crd-autoregister controller
I0803 14:27:14.340764       1 shared_informer.go:350] "Waiting for caches to sync" controller="crd-autoregister"
I0803 14:27:14.340796       1 dynamic_cafile_content.go:161] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0803 14:27:14.340834       1 dynamic_cafile_content.go:161] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0803 14:27:14.340943       1 controller.go:142] Starting OpenAPI controller
I0803 14:27:14.340962       1 controller.go:90] Starting OpenAPI V3 controller
I0803 14:27:14.340974       1 naming_controller.go:299] Starting NamingConditionController
I0803 14:27:14.340985       1 establishing_controller.go:81] Starting EstablishingController
I0803 14:27:14.341393       1 nonstructuralschema_controller.go:195] Starting NonStructuralSchemaConditionController
I0803 14:27:14.341413       1 apiapproval_controller.go:189] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0803 14:27:14.341425       1 crd_finalizer.go:269] Starting CRDFinalizer
E0803 14:27:14.427959       1 controller.go:145] "Failed to ensure lease exists, will retry" err="namespaces \"kube-system\" not found" interval="200ms"
I0803 14:27:14.437362       1 apf_controller.go:382] Running API Priority and Fairness config worker
I0803 14:27:14.437379       1 apf_controller.go:385] Running API Priority and Fairness periodic rebalancing process
I0803 14:27:14.437442       1 cache.go:39] Caches are synced for RemoteAvailability controller
I0803 14:27:14.438435       1 shared_informer.go:357] "Caches are synced" controller="configmaps"
I0803 14:27:14.438680       1 cache.go:39] Caches are synced for LocalAvailability controller
I0803 14:27:14.438973       1 shared_informer.go:357] "Caches are synced" controller="cluster_authentication_trust_controller"
I0803 14:27:14.438993       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0803 14:27:14.439036       1 handler_discovery.go:451] Starting ResourceDiscoveryManager
I0803 14:27:14.439051       1 shared_informer.go:357] "Caches are synced" controller="ipallocator-repair-controller"
I0803 14:27:14.439422       1 shared_informer.go:357] "Caches are synced" controller="kubernetes-service-cidr-controller"
I0803 14:27:14.439438       1 default_servicecidr_controller.go:165] Creating default ServiceCIDR with CIDRs: [10.96.0.0/12]
I0803 14:27:14.440802       1 shared_informer.go:357] "Caches are synced" controller="crd-autoregister"
I0803 14:27:14.440991       1 aggregator.go:171] initial CRD sync complete...
I0803 14:27:14.441073       1 autoregister_controller.go:144] Starting autoregister controller
I0803 14:27:14.441139       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0803 14:27:14.441202       1 cache.go:39] Caches are synced for autoregister controller
I0803 14:27:14.462575       1 shared_informer.go:357] "Caches are synced" controller="node_authorizer"
I0803 14:27:14.468864       1 shared_informer.go:357] "Caches are synced" controller="*generic.policySource[*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicy,*k8s.io/api/admissionregistration/v1.ValidatingAdmissionPolicyBinding,k8s.io/apiserver/pkg/admission/plugin/policy/validating.Validator]"
I0803 14:27:14.468883       1 policy_source.go:240] refreshing policies
E0803 14:27:14.490733       1 controller.go:148] "Unhandled Error" err="while syncing ConfigMap \"kube-system/kube-apiserver-legacy-service-account-token-tracking\", err: namespaces \"kube-system\" not found" logger="UnhandledError"
I0803 14:27:14.539816       1 controller.go:667] quota admission added evaluator for: namespaces
I0803 14:27:14.549026       1 cidrallocator.go:301] created ClusterIP allocator for Service CIDR 10.96.0.0/12
I0803 14:27:14.549354       1 default_servicecidr_controller.go:214] Setting default ServiceCIDR condition Ready to True
I0803 14:27:14.553684       1 cidrallocator.go:277] updated ClusterIP allocator for Service CIDR 10.96.0.0/12
I0803 14:27:14.554114       1 default_servicecidr_controller.go:136] Shutting down kubernetes-service-cidr-controller
I0803 14:27:14.638030       1 controller.go:667] quota admission added evaluator for: leases.coordination.k8s.io
I0803 14:27:15.345397       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I0803 14:27:15.350641       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I0803 14:27:15.350657       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0803 14:27:15.718121       1 controller.go:667] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0803 14:27:15.744068       1 controller.go:667] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0803 14:27:15.851634       1 alloc.go:328] "allocated clusterIPs" service="default/kubernetes" clusterIPs={"IPv4":"10.96.0.1"}
W0803 14:27:15.858914       1 lease.go:265] Resetting endpoints for master service "kubernetes" to [192.168.58.2]
I0803 14:27:15.860022       1 controller.go:667] quota admission added evaluator for: endpoints
I0803 14:27:15.863000       1 controller.go:667] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0803 14:27:16.368114       1 controller.go:667] quota admission added evaluator for: serviceaccounts
I0803 14:27:16.758388       1 controller.go:667] quota admission added evaluator for: deployments.apps
I0803 14:27:16.770076       1 alloc.go:328] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs={"IPv4":"10.96.0.10"}
I0803 14:27:16.777965       1 controller.go:667] quota admission added evaluator for: daemonsets.apps
I0803 14:27:21.468269       1 controller.go:667] quota admission added evaluator for: replicasets.apps
I0803 14:27:22.071165       1 cidrallocator.go:277] updated ClusterIP allocator for Service CIDR 10.96.0.0/12
I0803 14:27:22.075028       1 cidrallocator.go:277] updated ClusterIP allocator for Service CIDR 10.96.0.0/12
I0803 14:27:22.116401       1 controller.go:667] quota admission added evaluator for: controllerrevisions.apps


==> kube-controller-manager [e41e6b144155] <==
I0803 14:27:20.816030       1 garbagecollector.go:144] "Starting controller" logger="garbage-collector-controller" controller="garbagecollector"
I0803 14:27:20.816072       1 shared_informer.go:350] "Waiting for caches to sync" controller="garbage collector"
I0803 14:27:20.816104       1 graph_builder.go:351] "Running" logger="garbage-collector-controller" component="GraphBuilder"
I0803 14:27:20.816250       1 controllermanager.go:778] "Started controller" controller="garbage-collector-controller"
I0803 14:27:20.866244       1 controllermanager.go:778] "Started controller" controller="certificatesigningrequest-cleaner-controller"
I0803 14:27:20.866351       1 cleaner.go:83] "Starting CSR cleaner controller" logger="certificatesigningrequest-cleaner-controller"
I0803 14:27:20.875250       1 shared_informer.go:350] "Waiting for caches to sync" controller="resource quota"
I0803 14:27:20.903515       1 shared_informer.go:357] "Caches are synced" controller="namespace"
I0803 14:27:20.915579       1 shared_informer.go:357] "Caches are synced" controller="HPA"
I0803 14:27:20.917791       1 shared_informer.go:357] "Caches are synced" controller="disruption"
I0803 14:27:20.917821       1 shared_informer.go:357] "Caches are synced" controller="crt configmap"
I0803 14:27:20.918967       1 shared_informer.go:357] "Caches are synced" controller="cronjob"
I0803 14:27:20.920098       1 shared_informer.go:357] "Caches are synced" controller="TTL after finished"
I0803 14:27:20.921240       1 shared_informer.go:357] "Caches are synced" controller="endpoint_slice_mirroring"
I0803 14:27:20.921241       1 shared_informer.go:357] "Caches are synced" controller="deployment"
I0803 14:27:20.923393       1 shared_informer.go:357] "Caches are synced" controller="ReplicaSet"
I0803 14:27:20.929316       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrsigning-kubelet-serving"
I0803 14:27:20.931594       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrsigning-kubelet-client"
I0803 14:27:20.933779       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrsigning-legacy-unknown"
I0803 14:27:20.933874       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrsigning-kube-apiserver-client"
I0803 14:27:20.934996       1 shared_informer.go:357] "Caches are synced" controller="certificate-csrapproving"
I0803 14:27:20.966742       1 shared_informer.go:357] "Caches are synced" controller="service account"
I0803 14:27:20.969087       1 shared_informer.go:350] "Waiting for caches to sync" controller="garbage collector"
I0803 14:27:20.969147       1 shared_informer.go:357] "Caches are synced" controller="endpoint"
I0803 14:27:20.970665       1 shared_informer.go:357] "Caches are synced" controller="bootstrap_signer"
I0803 14:27:20.971148       1 shared_informer.go:357] "Caches are synced" controller="job"
I0803 14:27:20.971296       1 shared_informer.go:357] "Caches are synced" controller="ClusterRoleAggregator"
I0803 14:27:20.973161       1 shared_informer.go:357] "Caches are synced" controller="ReplicationController"
I0803 14:27:20.975247       1 shared_informer.go:357] "Caches are synced" controller="legacy-service-account-token-cleaner"
I0803 14:27:20.977859       1 shared_informer.go:357] "Caches are synced" controller="ephemeral"
I0803 14:27:20.985381       1 shared_informer.go:357] "Caches are synced" controller="expand"
I0803 14:27:21.019625       1 shared_informer.go:357] "Caches are synced" controller="PVC protection"
I0803 14:27:21.021968       1 shared_informer.go:357] "Caches are synced" controller="PV protection"
I0803 14:27:21.070345       1 shared_informer.go:357] "Caches are synced" controller="stateful set"
I0803 14:27:21.074964       1 actual_state_of_world.go:541] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"minikube\" does not exist"
I0803 14:27:21.082251       1 shared_informer.go:357] "Caches are synced" controller="service-cidr-controller"
I0803 14:27:21.090533       1 shared_informer.go:357] "Caches are synced" controller="taint-eviction-controller"
I0803 14:27:21.110808       1 shared_informer.go:357] "Caches are synced" controller="daemon sets"
I0803 14:27:21.117268       1 shared_informer.go:357] "Caches are synced" controller="persistent volume"
I0803 14:27:21.121738       1 shared_informer.go:357] "Caches are synced" controller="endpoint_slice"
I0803 14:27:21.123369       1 shared_informer.go:357] "Caches are synced" controller="attach detach"
I0803 14:27:21.165624       1 shared_informer.go:357] "Caches are synced" controller="taint"
I0803 14:27:21.165682       1 node_lifecycle_controller.go:1221] "Initializing eviction metric for zone" logger="node-lifecycle-controller" zone=""
I0803 14:27:21.165725       1 node_lifecycle_controller.go:873] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="minikube"
I0803 14:27:21.165748       1 node_lifecycle_controller.go:1067] "Controller detected that zone is now in new state" logger="node-lifecycle-controller" zone="" newState="Normal"
I0803 14:27:21.170322       1 shared_informer.go:357] "Caches are synced" controller="GC"
I0803 14:27:21.171583       1 shared_informer.go:357] "Caches are synced" controller="node"
I0803 14:27:21.171636       1 range_allocator.go:177] "Sending events to api server" logger="node-ipam-controller"
I0803 14:27:21.171662       1 range_allocator.go:183] "Starting range CIDR allocator" logger="node-ipam-controller"
I0803 14:27:21.171669       1 shared_informer.go:350] "Waiting for caches to sync" controller="cidrallocator"
I0803 14:27:21.171676       1 shared_informer.go:357] "Caches are synced" controller="cidrallocator"
I0803 14:27:21.172382       1 shared_informer.go:357] "Caches are synced" controller="TTL"
I0803 14:27:21.187628       1 range_allocator.go:428] "Set node PodCIDR" logger="node-ipam-controller" node="minikube" podCIDRs=["10.244.0.0/24"]
I0803 14:27:21.219053       1 shared_informer.go:357] "Caches are synced" controller="resource quota"
I0803 14:27:21.276014       1 shared_informer.go:357] "Caches are synced" controller="resource quota"
I0803 14:27:21.318122       1 shared_informer.go:357] "Caches are synced" controller="validatingadmissionpolicy-status"
I0803 14:27:21.717166       1 shared_informer.go:357] "Caches are synced" controller="garbage collector"
I0803 14:27:21.717190       1 garbagecollector.go:154] "Garbage collector: all resource monitors have synced" logger="garbage-collector-controller"
I0803 14:27:21.717195       1 garbagecollector.go:157] "Proceeding to collect garbage" logger="garbage-collector-controller"
I0803 14:27:21.770300       1 shared_informer.go:357] "Caches are synced" controller="garbage collector"


==> kube-proxy [65b0940d0a7b] <==
I0803 14:27:22.875901       1 server_linux.go:63] "Using iptables proxy"
I0803 14:27:23.113041       1 server.go:715] "Successfully retrieved node IP(s)" IPs=["192.168.58.2"]
E0803 14:27:23.113113       1 server.go:245] "Kube-proxy configuration may be incomplete or incorrect" err="nodePortAddresses is unset; NodePort connections will be accepted on all local IPs. Consider using `--nodeport-addresses primary`"
I0803 14:27:23.140448       1 server.go:254] "kube-proxy running in dual-stack mode" primary ipFamily="IPv4"
I0803 14:27:23.140482       1 server_linux.go:145] "Using iptables Proxier"
I0803 14:27:23.144039       1 proxier.go:243] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses" ipFamily="IPv4"
I0803 14:27:23.144208       1 server.go:516] "Version info" version="v1.33.1"
I0803 14:27:23.144234       1 server.go:518] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0803 14:27:23.145441       1 config.go:199] "Starting service config controller"
I0803 14:27:23.145454       1 shared_informer.go:350] "Waiting for caches to sync" controller="service config"
I0803 14:27:23.146154       1 config.go:105] "Starting endpoint slice config controller"
I0803 14:27:23.146199       1 config.go:329] "Starting node config controller"
I0803 14:27:23.149750       1 shared_informer.go:350] "Waiting for caches to sync" controller="node config"
I0803 14:27:23.146161       1 shared_informer.go:350] "Waiting for caches to sync" controller="endpoint slice config"
I0803 14:27:23.146427       1 config.go:440] "Starting serviceCIDR config controller"
I0803 14:27:23.149914       1 shared_informer.go:350] "Waiting for caches to sync" controller="serviceCIDR config"
I0803 14:27:23.246321       1 shared_informer.go:357] "Caches are synced" controller="service config"
I0803 14:27:23.250685       1 shared_informer.go:357] "Caches are synced" controller="serviceCIDR config"
I0803 14:27:23.250757       1 shared_informer.go:357] "Caches are synced" controller="node config"
I0803 14:27:23.250767       1 shared_informer.go:357] "Caches are synced" controller="endpoint slice config"


==> kube-scheduler [dce08fd179a8] <==
I0803 14:27:13.313977       1 serving.go:386] Generated self-signed cert in-memory
W0803 14:27:14.361280       1 requestheader_controller.go:204] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0803 14:27:14.361299       1 authentication.go:397] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0803 14:27:14.361305       1 authentication.go:398] Continuing without authentication configuration. This may treat all requests as anonymous.
W0803 14:27:14.361308       1 authentication.go:399] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0803 14:27:14.416101       1 server.go:171] "Starting Kubernetes Scheduler" version="v1.33.1"
I0803 14:27:14.416118       1 server.go:173] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0803 14:27:14.417093       1 configmap_cafile_content.go:205] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0803 14:27:14.417106       1 shared_informer.go:350] "Waiting for caches to sync" controller="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0803 14:27:14.417212       1 secure_serving.go:211] Serving securely on 127.0.0.1:10259
I0803 14:27:14.417246       1 tlsconfig.go:243] "Starting DynamicServingCertificateController"
E0803 14:27:14.421052       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ConfigMap: configmaps \"extension-apiserver-authentication\" is forbidden: User \"system:kube-scheduler\" cannot list resource \"configmaps\" in API group \"\" in the namespace \"kube-system\"" logger="UnhandledError" reflector="runtime/asm_amd64.s:1700" type="*v1.ConfigMap"
E0803 14:27:14.421408       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Service: services is forbidden: User \"system:kube-scheduler\" cannot list resource \"services\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Service"
E0803 14:27:14.421447       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Node: nodes is forbidden: User \"system:kube-scheduler\" cannot list resource \"nodes\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Node"
E0803 14:27:14.421465       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"replicasets\" in API group \"apps\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicaSet"
E0803 14:27:14.421480       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csidrivers\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIDriver"
E0803 14:27:14.421512       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csistoragecapacities\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIStorageCapacity"
E0803 14:27:14.421532       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Pod: pods is forbidden: User \"system:kube-scheduler\" cannot list resource \"pods\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Pod"
E0803 14:27:14.421548       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"storageclasses\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StorageClass"
E0803 14:27:14.421564       1 reflector.go:200] "Failed to watch" err="failed to list *v1.VolumeAttachment: volumeattachments.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"volumeattachments\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.VolumeAttachment"
E0803 14:27:14.421592       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User \"system:kube-scheduler\" cannot list resource \"persistentvolumeclaims\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolumeClaim"
E0803 14:27:14.421609       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User \"system:kube-scheduler\" cannot list resource \"persistentvolumes\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume"
E0803 14:27:14.421624       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csinodes\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSINode"
E0803 14:27:14.421648       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Namespace: namespaces is forbidden: User \"system:kube-scheduler\" cannot list resource \"namespaces\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace"
E0803 14:27:14.421666       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User \"system:kube-scheduler\" cannot list resource \"poddisruptionbudgets\" in API group \"policy\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PodDisruptionBudget"
E0803 14:27:14.421687       1 reflector.go:200] "Failed to watch" err="failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User \"system:kube-scheduler\" cannot list resource \"replicationcontrollers\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.ReplicationController"
E0803 14:27:14.421839       1 reflector.go:200] "Failed to watch" err="failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User \"system:kube-scheduler\" cannot list resource \"statefulsets\" in API group \"apps\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.StatefulSet"
E0803 14:27:15.314207       1 reflector.go:200] "Failed to watch" err="failed to list *v1.Namespace: namespaces is forbidden: User \"system:kube-scheduler\" cannot list resource \"namespaces\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.Namespace"
E0803 14:27:15.361618       1 reflector.go:200] "Failed to watch" err="failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"csistoragecapacities\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.CSIStorageCapacity"
E0803 14:27:15.498938       1 reflector.go:200] "Failed to watch" err="failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User \"system:kube-scheduler\" cannot list resource \"persistentvolumes\" in API group \"\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.PersistentVolume"
E0803 14:27:15.550500       1 reflector.go:200] "Failed to watch" err="failed to list *v1.VolumeAttachment: volumeattachments.storage.k8s.io is forbidden: User \"system:kube-scheduler\" cannot list resource \"volumeattachments\" in API group \"storage.k8s.io\" at the cluster scope" logger="UnhandledError" reflector="k8s.io/client-go/informers/factory.go:160" type="*v1.VolumeAttachment"
I0803 14:27:15.817826       1 shared_informer.go:357] "Caches are synced" controller="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"


==> kubelet <==
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.718985    2315 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Aug 03 14:27:16 minikube kubelet[2315]: E0803 14:27:16.720753    2315 eviction_manager.go:267] "eviction manager: failed to check if we have separate container filesystem. Ignoring." err="no imagefs label for configured runtime"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.786777    2315 kubelet.go:3309] "Creating a mirror pod for static pod" pod="kube-system/kube-scheduler-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.786919    2315 kubelet.go:3309] "Creating a mirror pod for static pod" pod="kube-system/kube-apiserver-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.787009    2315 kubelet.go:3309] "Creating a mirror pod for static pod" pod="kube-system/kube-controller-manager-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.787125    2315 kubelet.go:3309] "Creating a mirror pod for static pod" pod="kube-system/etcd-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: E0803 14:27:16.795386    2315 kubelet.go:3311] "Failed creating a mirror pod" err="pods \"kube-apiserver-minikube\" already exists" pod="kube-system/kube-apiserver-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: E0803 14:27:16.795455    2315 kubelet.go:3311] "Failed creating a mirror pod" err="pods \"etcd-minikube\" already exists" pod="kube-system/etcd-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.819274    2315 kubelet_node_status.go:75] "Attempting to register node" node="minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.827522    2315 kubelet_node_status.go:124] "Node was previously registered" node="minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.828420    2315 kubelet_node_status.go:78] "Successfully registered node" node="minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972522    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/feee622ba49882ef945e2406d3ba86df-kubeconfig\") pod \"kube-scheduler-minikube\" (UID: \"feee622ba49882ef945e2406d3ba86df\") " pod="kube-system/kube-scheduler-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972550    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/fe925670c18db101e16e9f2572e23070-etcd-data\") pod \"etcd-minikube\" (UID: \"fe925670c18db101e16e9f2572e23070\") " pod="kube-system/etcd-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972563    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/0378f173c980f85a71d36305bacb0ad1-flexvolume-dir\") pod \"kube-controller-manager-minikube\" (UID: \"0378f173c980f85a71d36305bacb0ad1\") " pod="kube-system/kube-controller-manager-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972573    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/c871e6f7025c72d9d868cfe04d5aa4ac-k8s-certs\") pod \"kube-apiserver-minikube\" (UID: \"c871e6f7025c72d9d868cfe04d5aa4ac\") " pod="kube-system/kube-apiserver-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972581    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/c871e6f7025c72d9d868cfe04d5aa4ac-usr-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"c871e6f7025c72d9d868cfe04d5aa4ac\") " pod="kube-system/kube-apiserver-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972588    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/0378f173c980f85a71d36305bacb0ad1-kubeconfig\") pod \"kube-controller-manager-minikube\" (UID: \"0378f173c980f85a71d36305bacb0ad1\") " pod="kube-system/kube-controller-manager-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972596    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/0378f173c980f85a71d36305bacb0ad1-usr-local-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"0378f173c980f85a71d36305bacb0ad1\") " pod="kube-system/kube-controller-manager-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972603    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/fe925670c18db101e16e9f2572e23070-etcd-certs\") pod \"etcd-minikube\" (UID: \"fe925670c18db101e16e9f2572e23070\") " pod="kube-system/etcd-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972611    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/c871e6f7025c72d9d868cfe04d5aa4ac-ca-certs\") pod \"kube-apiserver-minikube\" (UID: \"c871e6f7025c72d9d868cfe04d5aa4ac\") " pod="kube-system/kube-apiserver-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972618    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/c871e6f7025c72d9d868cfe04d5aa4ac-etc-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"c871e6f7025c72d9d868cfe04d5aa4ac\") " pod="kube-system/kube-apiserver-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972686    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/c871e6f7025c72d9d868cfe04d5aa4ac-usr-local-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"c871e6f7025c72d9d868cfe04d5aa4ac\") " pod="kube-system/kube-apiserver-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972704    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/0378f173c980f85a71d36305bacb0ad1-etc-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"0378f173c980f85a71d36305bacb0ad1\") " pod="kube-system/kube-controller-manager-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972712    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/0378f173c980f85a71d36305bacb0ad1-ca-certs\") pod \"kube-controller-manager-minikube\" (UID: \"0378f173c980f85a71d36305bacb0ad1\") " pod="kube-system/kube-controller-manager-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972720    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/0378f173c980f85a71d36305bacb0ad1-k8s-certs\") pod \"kube-controller-manager-minikube\" (UID: \"0378f173c980f85a71d36305bacb0ad1\") " pod="kube-system/kube-controller-manager-minikube"
Aug 03 14:27:16 minikube kubelet[2315]: I0803 14:27:16.972728    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/0378f173c980f85a71d36305bacb0ad1-usr-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"0378f173c980f85a71d36305bacb0ad1\") " pod="kube-system/kube-controller-manager-minikube"
Aug 03 14:27:17 minikube kubelet[2315]: I0803 14:27:17.655653    2315 apiserver.go:52] "Watching apiserver"
Aug 03 14:27:17 minikube kubelet[2315]: I0803 14:27:17.672659    2315 desired_state_of_world_populator.go:158] "Finished populating initial desired state of world"
Aug 03 14:27:17 minikube kubelet[2315]: I0803 14:27:17.729714    2315 kubelet.go:3309] "Creating a mirror pod for static pod" pod="kube-system/etcd-minikube"
Aug 03 14:27:17 minikube kubelet[2315]: E0803 14:27:17.739042    2315 kubelet.go:3311] "Failed creating a mirror pod" err="pods \"etcd-minikube\" already exists" pod="kube-system/etcd-minikube"
Aug 03 14:27:17 minikube kubelet[2315]: I0803 14:27:17.766644    2315 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/etcd-minikube" podStartSLOduration=1.766628839 podStartE2EDuration="1.766628839s" podCreationTimestamp="2025-08-03 14:27:16 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-08-03 14:27:17.753306249 +0000 UTC m=+1.138038006" watchObservedRunningTime="2025-08-03 14:27:17.766628839 +0000 UTC m=+1.151360588"
Aug 03 14:27:17 minikube kubelet[2315]: I0803 14:27:17.766720    2315 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/kube-scheduler-minikube" podStartSLOduration=1.766717189 podStartE2EDuration="1.766717189s" podCreationTimestamp="2025-08-03 14:27:16 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-08-03 14:27:17.766524106 +0000 UTC m=+1.151255859" watchObservedRunningTime="2025-08-03 14:27:17.766717189 +0000 UTC m=+1.151448932"
Aug 03 14:27:17 minikube kubelet[2315]: I0803 14:27:17.791367    2315 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/kube-apiserver-minikube" podStartSLOduration=1.791350065 podStartE2EDuration="1.791350065s" podCreationTimestamp="2025-08-03 14:27:16 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-08-03 14:27:17.790180319 +0000 UTC m=+1.174912083" watchObservedRunningTime="2025-08-03 14:27:17.791350065 +0000 UTC m=+1.176081829"
Aug 03 14:27:17 minikube kubelet[2315]: I0803 14:27:17.810086    2315 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/kube-controller-manager-minikube" podStartSLOduration=1.810053215 podStartE2EDuration="1.810053215s" podCreationTimestamp="2025-08-03 14:27:16 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-08-03 14:27:17.800758589 +0000 UTC m=+1.185490340" watchObservedRunningTime="2025-08-03 14:27:17.810053215 +0000 UTC m=+1.194784971"
Aug 03 14:27:21 minikube kubelet[2315]: I0803 14:27:21.200013    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-k2grm\" (UniqueName: \"kubernetes.io/projected/13edaa56-aa6b-4484-bc76-661bdc141313-kube-api-access-k2grm\") pod \"storage-provisioner\" (UID: \"13edaa56-aa6b-4484-bc76-661bdc141313\") " pod="kube-system/storage-provisioner"
Aug 03 14:27:21 minikube kubelet[2315]: I0803 14:27:21.201625    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/host-path/13edaa56-aa6b-4484-bc76-661bdc141313-tmp\") pod \"storage-provisioner\" (UID: \"13edaa56-aa6b-4484-bc76-661bdc141313\") " pod="kube-system/storage-provisioner"
Aug 03 14:27:21 minikube kubelet[2315]: E0803 14:27:21.311505    2315 projected.go:289] Couldn't get configMap kube-system/kube-root-ca.crt: configmap "kube-root-ca.crt" not found
Aug 03 14:27:21 minikube kubelet[2315]: E0803 14:27:21.311528    2315 projected.go:194] Error preparing data for projected volume kube-api-access-k2grm for pod kube-system/storage-provisioner: configmap "kube-root-ca.crt" not found
Aug 03 14:27:21 minikube kubelet[2315]: E0803 14:27:21.311577    2315 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/projected/13edaa56-aa6b-4484-bc76-661bdc141313-kube-api-access-k2grm podName:13edaa56-aa6b-4484-bc76-661bdc141313 nodeName:}" failed. No retries permitted until 2025-08-03 14:27:21.811562158 +0000 UTC m=+5.196293915 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "kube-api-access-k2grm" (UniqueName: "kubernetes.io/projected/13edaa56-aa6b-4484-bc76-661bdc141313-kube-api-access-k2grm") pod "storage-provisioner" (UID: "13edaa56-aa6b-4484-bc76-661bdc141313") : configmap "kube-root-ca.crt" not found
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.208528    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/e63c5657-e0c6-4c51-8c73-c688bc668d13-kube-proxy\") pod \"kube-proxy-nnzdq\" (UID: \"e63c5657-e0c6-4c51-8c73-c688bc668d13\") " pod="kube-system/kube-proxy-nnzdq"
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.208552    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/e63c5657-e0c6-4c51-8c73-c688bc668d13-xtables-lock\") pod \"kube-proxy-nnzdq\" (UID: \"e63c5657-e0c6-4c51-8c73-c688bc668d13\") " pod="kube-system/kube-proxy-nnzdq"
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.208560    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/e63c5657-e0c6-4c51-8c73-c688bc668d13-lib-modules\") pod \"kube-proxy-nnzdq\" (UID: \"e63c5657-e0c6-4c51-8c73-c688bc668d13\") " pod="kube-system/kube-proxy-nnzdq"
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.208569    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-wvbb2\" (UniqueName: \"kubernetes.io/projected/e63c5657-e0c6-4c51-8c73-c688bc668d13-kube-api-access-wvbb2\") pod \"kube-proxy-nnzdq\" (UID: \"e63c5657-e0c6-4c51-8c73-c688bc668d13\") " pod="kube-system/kube-proxy-nnzdq"
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.309971    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/dea2e562-9e1a-4482-b67e-88d34ecbdee9-config-volume\") pod \"coredns-674b8bbfcf-wqkrt\" (UID: \"dea2e562-9e1a-4482-b67e-88d34ecbdee9\") " pod="kube-system/coredns-674b8bbfcf-wqkrt"
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.310010    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-52vz8\" (UniqueName: \"kubernetes.io/projected/65329bd2-2e43-4242-b227-eb45d012954f-kube-api-access-52vz8\") pod \"coredns-674b8bbfcf-tdcd5\" (UID: \"65329bd2-2e43-4242-b227-eb45d012954f\") " pod="kube-system/coredns-674b8bbfcf-tdcd5"
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.310043    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/65329bd2-2e43-4242-b227-eb45d012954f-config-volume\") pod \"coredns-674b8bbfcf-tdcd5\" (UID: \"65329bd2-2e43-4242-b227-eb45d012954f\") " pod="kube-system/coredns-674b8bbfcf-tdcd5"
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.310058    2315 reconciler_common.go:251] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-gslqg\" (UniqueName: \"kubernetes.io/projected/dea2e562-9e1a-4482-b67e-88d34ecbdee9-kube-api-access-gslqg\") pod \"coredns-674b8bbfcf-wqkrt\" (UID: \"dea2e562-9e1a-4482-b67e-88d34ecbdee9\") " pod="kube-system/coredns-674b8bbfcf-wqkrt"
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.817165    2315 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="a9936dc00d22ff1a2714579d55abc03dfd55d136f60266642354ca134f8663c8"
Aug 03 14:27:22 minikube kubelet[2315]: I0803 14:27:22.857194    2315 pod_container_deletor.go:80] "Container not found in pod's containers" containerID="ffbb834df710365a5284fa1c73cbbfb7999947254d0414aba5a43398e242cf55"
Aug 03 14:27:23 minikube kubelet[2315]: I0803 14:27:23.882556    2315 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/storage-provisioner" podStartSLOduration=6.882539749 podStartE2EDuration="6.882539749s" podCreationTimestamp="2025-08-03 14:27:17 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-08-03 14:27:22.870020934 +0000 UTC m=+6.254752692" watchObservedRunningTime="2025-08-03 14:27:23.882539749 +0000 UTC m=+7.267271500"
Aug 03 14:27:23 minikube kubelet[2315]: I0803 14:27:23.896306    2315 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/coredns-674b8bbfcf-tdcd5" podStartSLOduration=1.896288575 podStartE2EDuration="1.896288575s" podCreationTimestamp="2025-08-03 14:27:22 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-08-03 14:27:23.882691643 +0000 UTC m=+7.267423399" watchObservedRunningTime="2025-08-03 14:27:23.896288575 +0000 UTC m=+7.281020324"
Aug 03 14:27:23 minikube kubelet[2315]: I0803 14:27:23.911519    2315 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/coredns-674b8bbfcf-wqkrt" podStartSLOduration=1.911505754 podStartE2EDuration="1.911505754s" podCreationTimestamp="2025-08-03 14:27:22 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-08-03 14:27:23.898757519 +0000 UTC m=+7.283489283" watchObservedRunningTime="2025-08-03 14:27:23.911505754 +0000 UTC m=+7.296237509"
Aug 03 14:27:24 minikube kubelet[2315]: I0803 14:27:24.890677    2315 prober_manager.go:312] "Failed to trigger a manual run" probe="Readiness"
Aug 03 14:27:24 minikube kubelet[2315]: I0803 14:27:24.891260    2315 prober_manager.go:312] "Failed to trigger a manual run" probe="Readiness"
Aug 03 14:27:26 minikube kubelet[2315]: I0803 14:27:26.103448    2315 pod_startup_latency_tracker.go:104] "Observed pod startup duration" pod="kube-system/kube-proxy-nnzdq" podStartSLOduration=4.103432687 podStartE2EDuration="4.103432687s" podCreationTimestamp="2025-08-03 14:27:22 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-08-03 14:27:23.915088922 +0000 UTC m=+7.299820676" watchObservedRunningTime="2025-08-03 14:27:26.103432687 +0000 UTC m=+9.488164452"
Aug 03 14:27:26 minikube kubelet[2315]: I0803 14:27:26.649763    2315 prober_manager.go:312] "Failed to trigger a manual run" probe="Readiness"
Aug 03 14:27:27 minikube kubelet[2315]: I0803 14:27:27.068141    2315 kuberuntime_manager.go:1746] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Aug 03 14:27:27 minikube kubelet[2315]: I0803 14:27:27.069902    2315 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Aug 03 14:27:30 minikube kubelet[2315]: I0803 14:27:30.998831    2315 prober_manager.go:312] "Failed to trigger a manual run" probe="Readiness"
Aug 03 14:27:53 minikube kubelet[2315]: I0803 14:27:53.081611    2315 scope.go:117] "RemoveContainer" containerID="2f02e615249f809ff067127678609798a23a56477c2b9a07642027e66b1ff18a"

